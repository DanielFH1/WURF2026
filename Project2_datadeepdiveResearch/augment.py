import json
import os
import shutil
from PIL import Image
from tqdm import tqdm

# ================= CONFIGURATION =================
# ì‘ì—… ê²½ë¡œ ì„¤ì • (ì‚¬ìš©ì ê²½ë¡œ ê¸°ë°˜)
BASE_DIR = "/nas_data2/seungwoo/2/ViewSpatial-Bench"
INPUT_JSONL = os.path.join(BASE_DIR, "data_train_scene_split/train.jsonl")
OUTPUT_JSONL = os.path.join(BASE_DIR, "data_train_scene_split/train_augmented.jsonl")

# ìƒˆë¡œ ìƒì„±ë  ì¦ê°• ì´ë¯¸ì§€ê°€ ì €ì¥ë  í´ë”
AUG_IMG_DIR = os.path.join(BASE_DIR, "augmented_images")

# ë°©í–¥ ë§¤í•‘ (ëŒ€ì†Œë¬¸ì ì£¼ì˜)
FLIP_MAPPING = {
    "Left": "Right",
    "Right": "Left",
    "Front-Left": "Front-Right",
    "Front-Right": "Front-Left",
    "Back-Left": "Back-Right",
    "Back-Right": "Back-Left",
    "left": "right",
    "right": "left",
    # Front, Backì€ ìœ ì§€
    "Front": "Front",
    "Back": "Back",
    "front": "front",
    "back": "back"
}
# =================================================

def ensure_dir(directory):
    if not os.path.exists(directory):
        os.makedirs(directory)

def swap_text(text):
    """í…ìŠ¤íŠ¸(ì§ˆë¬¸/ë‹µë³€) ë‚´ì˜ ë°©í–¥ ë‹¨ì–´ë¥¼ ë°˜ì „ì‹œí‚µë‹ˆë‹¤."""
    # ê°„ë‹¨í•œ ë‹¨ì–´ ì¹˜í™˜ (ë³µì¡í•œ ë¬¸ì¥ì¼ ê²½ìš° ì •êµí•œ í† í¬ë‚˜ì´ì§• í•„ìš”í•  ìˆ˜ ìˆìŒ)
    words = text.split()
    new_words = []
    for word in words:
        # êµ¬ë‘ì  ì œê±° ë“±ì€ ìƒí™©ì— ë§ì¶° ì²˜ë¦¬ (ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœ ì¹˜í™˜)
        clean_word = word.strip(".,?!")
        if clean_word in FLIP_MAPPING:
            # ë§¤í•‘ëœ ë‹¨ì–´ë¡œ êµì²´ (ì›ë˜ êµ¬ë‘ì  ë“± ìœ ì§€ í•„ìš” ì‹œ ì¶”ê°€ ë¡œì§ í•„ìš”í•˜ì§€ë§Œ, ë³´í†µ ë¼ë²¨ì€ ë‹¨ì–´ ìì²´ì„)
            replaced = FLIP_MAPPING[clean_word]
            new_words.append(word.replace(clean_word, replaced))
        else:
            new_words.append(word)
    return " ".join(new_words)

def process_augmentation():
    print(f"ğŸš€ Starting Horizontal Flip Augmentation...")
    print(f"ğŸ“‚ Reading from: {INPUT_JSONL}")
    
    ensure_dir(AUG_IMG_DIR)
    
    new_entries = []
    
    # 1. ì›ë³¸ ë°ì´í„° ë¡œë“œ
    with open(INPUT_JSONL, 'r', encoding='utf-8') as f:
        lines = f.readlines()

    print(f"ğŸ“Š Total original samples: {len(lines)}")
    
    # 2. ë°ì´í„° ì²˜ë¦¬ ë£¨í”„
    for line in tqdm(lines, desc="Augmenting"):
        entry = json.loads(line)
        
        # ì›ë³¸ ë°ì´í„°ëŠ” ê·¸ëŒ€ë¡œ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ (ë°ì´í„°ì…‹ 2ë°° í™•ì¥ì„ ìœ„í•´)
        new_entries.append(entry)
        
        # --- ì¦ê°• ë°ì´í„° ìƒì„± ---
        aug_entry = entry.copy()
        
        # ì´ë¯¸ì§€ ê²½ë¡œ ì‹ë³„ (ë°ì´í„°ì…‹ êµ¬ì¡°ì— ë”°ë¼ í‚¤ê°’ í™•ì¸ í•„ìš”, ë³´í†µ 'image' or 'image_path')
        img_filename = entry.get('image') or entry.get('image_path')
        
        if not img_filename:
            continue # ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ ìŠ¤í‚µ

        # ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸° (COCO vs Scannet ê²½ë¡œ ì²˜ë¦¬)
        # ì´ë¯¸ì§€ íŒŒì¼ëª…ì´ ì „ì²´ ê²½ë¡œì¸ì§€, íŒŒì¼ëª…ë§Œ ìˆëŠ”ì§€ì— ë”°ë¼ ë‹¤ë¦„.
        # ì¼ë‹¨ í˜„ì¬ í´ë” êµ¬ì¡°ìƒ ì•„ë˜ ê²½ë¡œë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ íƒìƒ‰
        potential_paths = [
            os.path.join(BASE_DIR, img_filename),
            os.path.join(BASE_DIR, "val2017", img_filename),
            os.path.join(BASE_DIR, "scannetv2_val", img_filename)
        ]
        
        src_img_path = None
        for path in potential_paths:
            if os.path.exists(path):
                src_img_path = path
                break
        
        if src_img_path is None:
            # íŒŒì¼ì„ ëª» ì°¾ìœ¼ë©´ ì¦ê°• í¬ê¸°í•˜ê³  ì›ë³¸ë§Œ ìœ ì§€
            continue

        # 1. ì´ë¯¸ì§€ ë¡œë“œ ë° ì¢Œìš° ë°˜ì „
        try:
            with Image.open(src_img_path) as img:
                flipped_img = img.transpose(Image.FLIP_LEFT_RIGHT)
                
                # ìƒˆ íŒŒì¼ëª… ìƒì„± (ì˜ˆ: abc.jpg -> abc_flip.jpg)
                name, ext = os.path.splitext(os.path.basename(img_filename))
                new_filename = f"{name}_flip{ext}"
                save_path = os.path.join(AUG_IMG_DIR, new_filename)
                
                # ì´ë¯¸ì§€ ì €ì¥
                flipped_img.save(save_path)
                
                # ì¦ê°•ëœ ì—”íŠ¸ë¦¬ì— ìƒˆ ì´ë¯¸ì§€ ê²½ë¡œ(íŒŒì¼ëª…) ì—…ë°ì´íŠ¸
                # í•™ìŠµ ë¡œë”ê°€ 'augmented_images' í´ë”ë„ ë³¼ ìˆ˜ ìˆê²Œ ê²½ë¡œ ì¡°ì • í•„ìš”
                # ì—¬ê¸°ì„œëŠ” ìƒëŒ€ ê²½ë¡œë¡œ 'augmented_images/filename' ì €ì¥
                aug_entry['image'] = os.path.join("augmented_images", new_filename)
                
        except Exception as e:
            print(f"Error processing image {src_img_path}: {e}")
            continue

        # 2. ì •ë‹µ(Label/Answer) ë°˜ì „
        # ë°ì´í„°ì…‹ í¬ë§·ì— ë”°ë¼ 'answer', 'label', 'conversations' ë“± í‚¤ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ
        # ì¼ë°˜ì ì¸ VQA í¬ë§·ì¸ 'answer'ë¼ê³  ê°€ì •í•˜ê³  ì²˜ë¦¬
        if 'answer' in aug_entry:
            aug_entry['answer'] = swap_text(aug_entry['answer'])
            
        # ë§Œì•½ conversations(LLaVA í¬ë§·) êµ¬ì¡°ë¼ë©´ ì•„ë˜ ì£¼ì„ í•´ì œí•˜ì—¬ ì‚¬ìš©
        # if 'conversations' in aug_entry:
        #     for conv in aug_entry['conversations']:
        #         if conv['from'] == 'gpt': # ëª¨ë¸ì˜ ë‹µë³€ ë¶€ë¶„ë§Œ ìˆ˜ì •
        #             conv['value'] = swap_text(conv['value'])

        # 3. ì§ˆë¬¸(Question) ë°˜ì „ ì—¬ë¶€
        # ì§ˆë¬¸ì— "What is on the left?" ê°™ì€ í‘œí˜„ì´ ìˆë‹¤ë©´ ì´ê²ƒë„ ë°”ê¿”ì•¼ í•¨ ("on the right?"ìœ¼ë¡œ)
        # ë…¼ë¦¬ì  ì •í•©ì„±ì„ ìœ„í•´ ì§ˆë¬¸ë„ swap_text ì²˜ë¦¬ ì¶”ì²œ
        if 'question' in aug_entry:
            aug_entry['question'] = swap_text(aug_entry['question'])

        # ì¦ê°•ëœ ì—”íŠ¸ë¦¬ ì¶”ê°€
        new_entries.append(aug_entry)

    # 3. ìƒˆë¡œìš´ JSONL ì €ì¥
    print(f"ğŸ’¾ Saving to: {OUTPUT_JSONL}")
    with open(OUTPUT_JSONL, 'w', encoding='utf-8') as f:
        for entry in new_entries:
            f.write(json.dumps(entry) + '\n')
            
    print(f"âœ¨ Done! Final dataset size: {len(new_entries)} (Original x 2)")
    print(f"âš ï¸ Checkpoint: Make sure your dataloader can read images from '{AUG_IMG_DIR}'")

if __name__ == "__main__":
    process_augmentation()