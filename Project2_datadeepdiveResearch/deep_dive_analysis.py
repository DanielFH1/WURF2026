import torch
import json
import os
import matplotlib.pyplot as plt
import textwrap
import re
from tqdm import tqdm
from PIL import Image, ImageDraw, ImageFont
from collections import defaultdict
from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor
from qwen_vl_utils import process_vision_info

# ================= ÏÑ§Ï†ï =================
# GPU 3Î≤à ÏÇ¨Ïö©
os.environ["CUDA_VISIBLE_DEVICES"] = "3"

MODEL_PATH = "./checkpoints/mvsm_baseline_merged"
TEST_FILE = "data_train_scene_split/test.json"
BASE_IMAGE_DIR = "/nas_data2/seungwoo/2/ViewSpatial-Bench"

# Í≤∞Í≥º Ï†ÄÏû• Í≤ΩÎ°ú
RESULT_DIR = "data_divedive_results/experiment_1"
os.makedirs(RESULT_DIR, exist_ok=True)
# ========================================

def get_font(size=40):
    """ÏÑúÎ≤Ñ ÌôòÍ≤ΩÏóêÏÑú ÌÅ∞ Ìè∞Ìä∏ Î°úÎìú"""
    font_paths = [
        "/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf",
        "/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf",
        "DejaVuSans-Bold.ttf",
        "arial.ttf"
    ]
    for path in font_paths:
        try:
            return ImageFont.truetype(path, size)
        except OSError:
            continue
    return ImageFont.load_default()

def clean_choice_text(text):
    return re.sub(r'^[A-Z]\.\s*', '', str(text)).strip()

def create_analysis_image(img_path, q_text, choices_list, answer_idx, pred_idx, is_correct, save_path):
    try:
        # 1. Ïù¥ÎØ∏ÏßÄ Î°úÎìú Î∞è Î¶¨ÏÇ¨Ïù¥Ï¶à (ÎÑàÎ¨¥ ÌÅ∞ Ïù¥ÎØ∏ÏßÄ Î∞©ÏßÄ)
        orig_img = Image.open(img_path).convert("RGB")
        max_img_width = 1400
        if orig_img.width > max_img_width:
            ratio = max_img_width / orig_img.width
            new_height = int(orig_img.height * ratio)
            orig_img = orig_img.resize((max_img_width, new_height), Image.Resampling.LANCZOS)
        
        img_w, img_h = orig_img.size
        
        # 2. Ìè∞Ìä∏ ÏÑ§Ï†ï
        font_title = get_font(50)
        font_normal = get_font(36)
        font_small = get_font(32)
        
        margin = 60
        line_spacing = 20
        section_spacing = 40
        
        # 3. Ï∫îÎ≤ÑÏä§ ÎÑàÎπÑ Í≤∞Ï†ï (Ïù¥ÎØ∏ÏßÄ ÎÑàÎπÑÎ≥¥Îã§ Ï∂©Î∂ÑÌûà ÌÅ¨Í≤å)
        canvas_w = max(img_w + margin * 2, 1600)
        
        # 4. ÌÖçÏä§Ìä∏ ÎÇ¥Ïö© Íµ¨ÏÑ±
        options_idx = "ABCDEFGHIJKLMNOPQRSTUVWXYZ"
        
        # Result ÏÑπÏÖò
        result_str = "‚úÖ CORRECT" if is_correct else "‚ùå WRONG"
        result_color = (0, 150, 0) if is_correct else (200, 0, 0)
        
        # Question ÏÑπÏÖò
        question_lines = textwrap.wrap(q_text, width=int((canvas_w - margin*2) / 20))
        
        # Options ÏÑπÏÖò (Í∞Å ÏÑ†ÏßÄÎ≥ÑÎ°ú Ï≤òÎ¶¨)
        formatted_choices = []
        for idx, raw_choice in enumerate(choices_list):
            letter = options_idx[idx]
            clean_text = clean_choice_text(raw_choice)
            
            # Î†àÏù¥Î∏î Í≤∞Ï†ï
            labels = []
            if letter == answer_idx:
                labels.append("Ground Truth")
            if letter == pred_idx:
                labels.append("Model Prediction")
            
            # ÏÑ†ÏßÄ ÌÖçÏä§Ìä∏ Íµ¨ÏÑ±
            label_str = f" ({', '.join(labels)})" if labels else ""
            choice_text = f"{letter}. {clean_text}{label_str}"
            
            # Í∏¥ ÏÑ†ÏßÄÎäî Ï§ÑÎ∞îÍøà
            wrapped = textwrap.wrap(choice_text, width=int((canvas_w - margin*2) / 20))
            formatted_choices.extend(wrapped)
        
        # 5. ÌÖçÏä§Ìä∏ ÏòÅÏó≠ ÎÜíÏù¥ Í≥ÑÏÇ∞
        dummy_img = Image.new("RGB", (1, 1))
        dummy_draw = ImageDraw.Draw(dummy_img)
        
        # Result ÎÜíÏù¥
        result_bbox = dummy_draw.textbbox((0, 0), result_str, font=font_title)
        result_h = result_bbox[3] - result_bbox[1]
        
        # Question ÎÜíÏù¥
        question_h = len(question_lines) * (36 + line_spacing)
        
        # Options ÎÜíÏù¥
        options_h = len(formatted_choices) * (32 + line_spacing)
        
        # Ï¥ù ÌÖçÏä§Ìä∏ ÏòÅÏó≠ ÎÜíÏù¥
        text_area_h = (margin + 
                       result_h + section_spacing + 
                       50 + line_spacing +  # "[Question]" Ìó§Îçî
                       question_h + section_spacing + 
                       50 + line_spacing +  # "[Options]" Ìó§Îçî
                       options_h + margin)
        
        # 6. ÏµúÏ¢Ö Ï∫îÎ≤ÑÏä§ ÏÉùÏÑ±
        canvas_h = img_h + text_area_h
        final_img = Image.new("RGB", (canvas_w, canvas_h), (255, 255, 255))
        draw = ImageDraw.Draw(final_img)
        
        # 7. Ïù¥ÎØ∏ÏßÄ Î∂ôÏù¥Í∏∞ (Ï§ëÏïô Ï†ïÎ†¨, ÎπÑÏú® Ïú†ÏßÄ)
        img_x = (canvas_w - img_w) // 2
        final_img.paste(orig_img, (img_x, 0))
        
        # 8. ÌÖçÏä§Ìä∏ Í∑∏Î¶¨Í∏∞
        curr_y = img_h + margin
        
        # Result
        draw.text((margin, curr_y), result_str, fill=result_color, font=font_title)
        curr_y += result_h + section_spacing
        
        # Question Ìó§Îçî
        draw.text((margin, curr_y), "[Question]", fill=(0, 0, 0), font=font_normal)
        curr_y += 50 + line_spacing
        
        # Question ÎÇ¥Ïö©
        for line in question_lines:
            draw.text((margin, curr_y), line, fill=(40, 40, 40), font=font_small)
            curr_y += 32 + line_spacing
        
        curr_y += section_spacing
        
        # Options Ìó§Îçî
        draw.text((margin, curr_y), "[Options]", fill=(0, 0, 0), font=font_normal)
        curr_y += 50 + line_spacing
        
        # Options ÎÇ¥Ïö© (Í∞ïÏ°∞ ÌëúÏãú)
        for choice_line in formatted_choices:
            # Ground TruthÎÇò PredictionÏù¥ Ìè¨Ìï®Îêú Ï§ÑÏùÄ Î∞∞Í≤ΩÏÉâ Ï∂îÍ∞Ä
            text_color = (40, 40, 40)
            if "Ground Truth" in choice_line or "Model Prediction" in choice_line:
                # Î∞∞Í≤Ω Î∞ïÏä§ Í∑∏Î¶¨Í∏∞
                bbox = draw.textbbox((margin, curr_y), choice_line, font=font_small)
                draw.rectangle(
                    [(bbox[0]-5, bbox[1]-2), (bbox[2]+5, bbox[3]+2)],
                    fill=(255, 255, 200) if "Ground Truth" in choice_line else (230, 230, 255)
                )
                text_color = (0, 0, 0)
            
            draw.text((margin, curr_y), choice_line, fill=text_color, font=font_small)
            curr_y += 32 + line_spacing

        # 9. Ï†ÄÏû•
        final_img.save(save_path, quality=95)
        
    except Exception as e:
        print(f"‚ö†Ô∏è Ïù¥ÎØ∏ÏßÄ Ï†ÄÏû• Ïã§Ìå® ({save_path}): {e}")

def run_analysis():
    print(f"ü§ñ Loading Model: {MODEL_PATH}")
    model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
        MODEL_PATH, torch_dtype=torch.bfloat16, device_map="auto"
    )
    processor = AutoProcessor.from_pretrained(MODEL_PATH)

    print(f"üìÇ Loading Data: {TEST_FILE}")
    with open(TEST_FILE, 'r') as f:
        dataset = json.load(f)

    stats = defaultdict(lambda: {'total': 0, 'correct': 0, 'errors': []})
    
    print("üöÄ Deep Dive Visual Analysis (Top-Bottom Layout)...")
    for idx, item in tqdm(enumerate(dataset), total=len(dataset)):
        # Ïù¥ÎØ∏ÏßÄ Í≤ΩÎ°ú Ï≤òÎ¶¨
        img_rel_path = item['image_path'][0] if isinstance(item['image_path'], list) else item['image_path']
        full_img_path = os.path.join(BASE_IMAGE_DIR, img_rel_path)
        
        if not os.path.exists(full_img_path):
             if img_rel_path.startswith("ViewSpatial-Bench/"):
                alt_path = full_img_path.replace("ViewSpatial-Bench/ViewSpatial-Bench/", "ViewSpatial-Bench/")
                if os.path.exists(alt_path):
                    full_img_path = alt_path

        # Îç∞Ïù¥ÌÑ∞ ÌååÏã±
        task_type = item.get('question_type', 'Unknown')
        question_main = item['question']
        raw_choices = item['choices']
        
        # ÏÑ†ÏßÄ Î¶¨Ïä§Ìä∏ ÌôïÎ≥¥
        formatted_choices = []
        options_idx = "ABCDEFGHIJKLMNOPQRSTUVWXYZ"
        
        if isinstance(raw_choices, list):
            choices_list_pure = raw_choices
            for i, c in enumerate(raw_choices): formatted_choices.append(f"{options_idx[i]}. {c}")
        else:
            try:
                import ast
                choices_list_pure = ast.literal_eval(raw_choices)
                for i, c in enumerate(choices_list_pure): formatted_choices.append(f"{options_idx[i]}. {c}")
            except:
                choices_list_pure = [raw_choices]
                formatted_choices.append(raw_choices)

        choices_str = "\n".join(formatted_choices)
        question_full = f"{question_main}\n{choices_str}\nAnswer with the option letter."
        answer_gt = item['answer'][0].upper()

        # Ï∂îÎ°†
        messages = [{"role": "user", "content": [{"type": "image", "image": full_img_path}, {"type": "text", "text": question_full}]}]
        text_input = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
        image_inputs, _ = process_vision_info(messages)
        inputs = processor(text=[text_input], images=image_inputs, padding=True, return_tensors="pt").to(model.device)
        
        with torch.no_grad():
            gen_ids = model.generate(**inputs, max_new_tokens=16)
        
        pred_text = processor.batch_decode(gen_ids, skip_special_tokens=True)[0].split("assistant\n")[-1].strip()
        pred_char = pred_text[0].upper() if pred_text else "X"

        # ÌÜµÍ≥Ñ
        is_correct = (pred_char == answer_gt)
        stats[task_type]['total'] += 1
        if is_correct:
            stats[task_type]['correct'] += 1
        else:
            stats[task_type]['errors'].append((answer_gt, pred_char, choices_list_pure))

        # Ï†ÄÏû•
        status_folder = "Correct" if is_correct else "Incorrect"
        save_dir = os.path.join(RESULT_DIR, task_type, status_folder)
        os.makedirs(save_dir, exist_ok=True)
        
        filename = f"{idx:04d}_GT-{answer_gt}_Pred-{pred_char}.jpg"
        
        # Í∞úÏÑ†Îêú Î†àÏù¥ÏïÑÏõÉ Ìï®Ïàò Ìò∏Ï∂ú
        create_analysis_image(
            full_img_path, 
            question_main, 
            choices_list_pure, 
            answer_gt, 
            pred_char, 
            is_correct, 
            os.path.join(save_dir, filename)
        )

    # Ï∞®Ìä∏ Î∞è Î¶¨Ìè¨Ìä∏ ÏÉùÏÑ±
    generate_report(stats)

def generate_report(stats):
    print("üìä Generating Final Report...")
    tasks = sorted(stats.keys())
    accuracies = []
    labels = []
    
    for t in tasks:
        correct = stats[t]['correct']
        total = stats[t]['total']
        acc = (correct / total) * 100 if total > 0 else 0
        accuracies.append(acc)
        labels.append(f"{acc:.1f}% ({correct}/{total})")
        
    plt.figure(figsize=(14, 8))
    bars = plt.barh(tasks, accuracies, color='#4A90E2', alpha=0.8)
    plt.xlabel('Accuracy (%)', fontsize=14, fontweight='bold')
    plt.title('Task-wise Accuracy (Baseline)', fontsize=16, fontweight='bold')
    plt.xlim(0, 115)
    plt.grid(axis='x', linestyle='--', alpha=0.3)
    
    for bar, label in zip(bars, labels):
        plt.text(bar.get_width() + 1, bar.get_y() + bar.get_height()/2, label, 
                 va='center', fontsize=12, fontweight='bold', color='black')
    
    plt.tight_layout()
    plt.savefig(os.path.join(RESULT_DIR, "accuracy_chart.svg"), format='svg')
    plt.savefig(os.path.join(RESULT_DIR, "accuracy_chart.png"), dpi=300)
    
    with open(os.path.join(RESULT_DIR, "error_analysis.txt"), "w") as f:
        f.write("=== Deep Dive Error Analysis ===\n\n")
        total_correct = sum(s['correct'] for s in stats.values())
        total_cnt = sum(s['total'] for s in stats.values())
        if total_cnt > 0:
            f.write(f"Overall Accuracy: {total_correct/total_cnt*100:.2f}% ({total_correct}/{total_cnt})\n\n")
        
        for task in tasks:
            f.write(f"## Task: {task}\n")
            errs = stats[task]['errors']
            f.write(f"  - Accuracy: {stats[task]['correct']/stats[task]['total']*100:.2f}%\n")
            
            semantic_patterns = defaultdict(int)
            options_idx = "ABCDEFGHIJKLMNOPQRSTUVWXYZ"
            for gt_char, pred_char, choices in errs:
                try:
                    gt_idx = options_idx.index(gt_char)
                    pred_idx = options_idx.index(pred_char)
                    gt_text = choices[gt_idx] if gt_idx < len(choices) else "Unknown"
                    pred_text = choices[pred_idx] if pred_idx < len(choices) else "Unknown"
                    semantic_patterns[f"'{gt_text}' -> '{pred_text}'"] += 1
                except:
                    semantic_patterns[f"{gt_char} -> {pred_char}"] += 1

            f.write("  - Top Confusion Patterns:\n")
            for p, c in sorted(semantic_patterns.items(), key=lambda x:x[1], reverse=True)[:10]:
                f.write(f"    {p}: {c} times\n")
            f.write("\n")
            
    print(f"‚úÖ Deep Dive ÏôÑÎ£å! Í≤∞Í≥º Ìè¥Îçî: {RESULT_DIR}")

if __name__ == "__main__":
    run_analysis()