import json
import os
import cv2
import re
import torch
from tqdm import tqdm
from ultralytics import YOLOWorld

# ================= CONFIGURATION =================
BASE_DIR = os.getcwd()
INPUT_JSONL = os.path.join(BASE_DIR, "data_train_scene_split/train.jsonl")
OUTPUT_JSONL = os.path.join(BASE_DIR, "data_train_scene_split/train_visual_prompt.jsonl")

# [í•µì‹¬] GPU ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ CPU ê°•ì œ ì‚¬ìš©
print("ğŸš€ Loading YOLO-World Model (CPU Mode)...")
model = YOLOWorld('yolov8s-worldv2.pt')

# =================================================

def extract_target_info(text):
    """
    ì§ˆë¬¸ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ íƒ€ê²Ÿ í´ë˜ìŠ¤ì™€ êµì²´í•  í…ìŠ¤íŠ¸ êµ¬ê°„ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    text_lower = text.lower()
    
    # 1. ì—­í•  ì´ì…í˜• ("Imagine you're the X", "As the X")
    match = re.search(r"(?:imagine you're|as|picture yourself as) (?:the |a |this )?(.+?) (?:in|looking|facing|within|photo)", text_lower)
    if match:
        raw_obj = match.group(1).strip()
        return raw_obj, raw_obj

    # 2. ê´€ì  ëª…ì‹œí˜• ("From the perspective of the X")
    match = re.search(r"from (?:the )?perspective of (?:the |this |a )?(.+?)(?:, | \?|\.|$)", text_lower)
    if match:
        raw_obj = match.group(1).strip()
        return raw_obj, raw_obj
    
    # 2-1. ì†Œìœ ê²© ê´€ì  ("From this woman's perspective")
    match = re.search(r"from (?:the |this |a )?(.+?)'s perspective", text_lower)
    if match:
        raw_obj = match.group(1).strip()
        return raw_obj, raw_obj

    # 3. ì‚¬ë¬¼ ê°„ ë¹„êµí˜• ("comparison to the X")
    match = re.search(r"(?:respect to|comparison to) (?:the |this |a )?(.+?)(?:\?|\.| in|$)", text_lower)
    if match:
        raw_obj = match.group(1).strip()
        return raw_obj, raw_obj

    return None, None

def draw_dynamic_box(image_path, target_class, save_path):
    """
    YOLOì—ê²Œ target_classë¥¼ ì°¾ê²Œ í•˜ê³  ë¹¨ê°„ ë°•ìŠ¤ë¥¼ ê·¸ë¦½ë‹ˆë‹¤. (CPU ëª¨ë“œ)
    """
    try:
        # [í•µì‹¬] í´ë˜ìŠ¤ ì„¤ì •
        model.set_classes([target_class])
        
        # [í•µì‹¬] device='cpu'ë¥¼ ëª…ì‹œí•´ì„œ CUDA ì—ëŸ¬ ì›ì²œ ì°¨ë‹¨
        results = model.predict(image_path, conf=0.05, verbose=False, device='cpu')
        result = results[0]

        if len(result.boxes) == 0:
            return False

        # ê°€ì¥ ì‹ ë¢°ë„ ë†’ì€ ê°ì²´ ì„ íƒ
        best_box = sorted(result.boxes, key=lambda x: x.conf[0], reverse=True)[0]
        x1, y1, x2, y2 = map(int, best_box.xyxy[0])

        img = cv2.imread(image_path)
        if img is None: 
            print(f"[OpenCV Fail] Cannot read image: {image_path}")
            return False
        
        # ë¹¨ê°„ ë°•ìŠ¤ ê·¸ë¦¬ê¸° (BGR)
        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255), 3)

        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        cv2.imwrite(save_path, img)
        return True

    except Exception as e:
        # ì—ëŸ¬ê°€ ë‚˜ë©´ ë­”ì§€ ì¶œë ¥
        print(f"\n[Error processing {target_class}] {e}")
        return False

def process_visual_prompt():
    print(f"ğŸš€ Starting Dynamic Visual Prompt Generation (Robust Mode)...")
    
    with open(INPUT_JSONL, 'r', encoding='utf-8') as f:
        lines = f.readlines()

    new_entries = []
    stats = {
        "total": len(lines),
        "success": 0,       
        "skip_no_target": 0, 
        "fail_detection": 0 
    }

    for line in tqdm(lines, desc="Processing"):
        entry = json.loads(line)
        new_entry = entry.copy()
        
        img_rel_path = None
        target_text_obj = None
        target_class = None
        replace_span = None
        
        # 1. í…ìŠ¤íŠ¸ ë¶„ì„ ë° íƒ€ê²Ÿ ì¶”ì¶œ
        if 'messages' in entry:
            for msg in new_entry['messages']:
                if msg['role'] == 'user':
                    for content in msg['content']:
                        if content['type'] == 'image':
                            img_rel_path = content['image']
                        if content['type'] == 'text':
                            t_cls, t_span = extract_target_info(content['text'])
                            if t_cls:
                                target_class = t_cls
                                replace_span = t_span
                                target_text_obj = content
                                
        elif 'image' in entry and 'question' in entry:
            img_rel_path = entry['image']
            t_cls, t_span = extract_target_info(entry['question'])
            if t_cls:
                target_class = t_cls
                replace_span = t_span
        
        # 2. íƒ€ê²Ÿ ì—†ìŒ ìŠ¤í‚µ
        if not target_class or not img_rel_path:
            new_entries.append(entry)
            stats["skip_no_target"] += 1
            continue

        # 3. ì´ë¯¸ì§€ ì²˜ë¦¬
        real_image_path = os.path.join(BASE_DIR, img_rel_path)
        save_rel_path = os.path.join("visual_prompt_images", img_rel_path)
        save_full_path = os.path.join(BASE_DIR, save_rel_path)

        is_detected = draw_dynamic_box(real_image_path, target_class, save_full_path)

        if is_detected:
            # 4. í…ìŠ¤íŠ¸ ìˆ˜ì •
            suffix = " in the red bounding box"
            try:
                if 'messages' in new_entry:
                    original_text = target_text_obj['text']
                    pattern = re.compile(re.escape(replace_span), re.IGNORECASE)
                    new_text = pattern.sub(f"{replace_span}{suffix}", original_text, count=1)
                    target_text_obj['text'] = new_text
                    
                    # ì´ë¯¸ì§€ ê²½ë¡œ ì—…ë°ì´íŠ¸
                    for msg in new_entry['messages']:
                        if msg['role'] == 'user':
                            for content in msg['content']:
                                if content['type'] == 'image':
                                    content['image'] = save_rel_path
                                    
                elif 'question' in new_entry:
                    original_text = new_entry['question']
                    pattern = re.compile(re.escape(replace_span), re.IGNORECASE)
                    new_entry['question'] = pattern.sub(f"{replace_span}{suffix}", original_text, count=1)
                    new_entry['image'] = save_rel_path
                
                new_entries.append(new_entry)
                stats["success"] += 1
            except Exception as e:
                print(f"[Text Mod Error] {e}")
                new_entries.append(entry)
                stats["fail_detection"] += 1
        else:
            new_entries.append(entry)
            stats["fail_detection"] += 1

    with open(OUTPUT_JSONL, 'w', encoding='utf-8') as f:
        for entry in new_entries:
            f.write(json.dumps(entry) + '\n')

    print(f"\nâœ¨ ì™„ë£Œ!")
    print(f" - ì´ ë°ì´í„°: {stats['total']}")
    print(f" - [ì„±ê³µ] Visual Prompt ì ìš©: {stats['success']} (ì´ ìˆ«ìê°€ ì¤‘ìš”í•¨)")
    print(f" - [ì œì™¸] íƒ€ê²Ÿ ì—†ìŒ: {stats['skip_no_target']}")
    print(f" - [ì‹¤íŒ¨] YOLO ê°ì§€ ì‹¤íŒ¨: {stats['fail_detection']}")
    print(f"ğŸ’¾ ì €ì¥ ê²½ë¡œ: {OUTPUT_JSONL}")

if __name__ == "__main__":
    process_visual_prompt()