import json
import os
import base64
import time
from tqdm import tqdm
from openai import OpenAI
import concurrent.futures

# ================= ì„¤ì • =================
# 1. ì‚¬ìš©í•  Teacher ëª¨ë¸ (API ë˜ëŠ” ë¡œì»¬ 72B ëª¨ë¸)
# API ì‚¬ìš© ì‹œ: "gpt-4o"
# ë¡œì»¬ ì‚¬ìš© ì‹œ (vLLM): "Qwen/Qwen2-VL-72B-Instruct" (ëª¨ë¸ëª…ì€ ì„œë²„ ì„¤ì • ë”°ë¦„)
MODEL_NAME = "gpt-4o" 
API_KEY = "sk-..."  # ì‹¤ì œ í‚¤ ì…ë ¥ í•„ìš”
BASE_URL = "https://api.openai.com/v1" # ë¡œì»¬ vLLM ì‚¬ìš© ì‹œ: "http://localhost:8000/v1"

# 2. ë°ì´í„° ê²½ë¡œ
BASE_DIR = os.getcwd()
INPUT_JSONL = os.path.join(BASE_DIR, "data_train_scene_split/train.jsonl") # ì›ë³¸ (ì´ë¯¸ì§€+ì§ˆë¬¸+ë‹¨ë‹µ)
OUTPUT_JSONL = os.path.join(BASE_DIR, "data_train_scene_split/train_real_cot.jsonl") # ê²°ê³¼ë¬¼

client = OpenAI(api_key=API_KEY, base_url=BASE_URL)
# =======================================

def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

def generate_reasoning(entry):
    """
    Teacher Modelì—ê²Œ ì •ë‹µì„ ì£¼ê³  ì¶”ë¡  ê³¼ì •ì„ ìƒì„±í•˜ê²Œ í•¨
    """
    try:
        # ë°ì´í„° íŒŒì‹±
        image_rel_path = ""
        question = ""
        correct_answer = ""
        
        # messages í¬ë§· íŒŒì‹±
        if 'messages' in entry:
            for msg in entry['messages']:
                if msg['role'] == 'user':
                    for content in msg['content']:
                        if content['type'] == 'image': image_rel_path = content['image']
                        if content['type'] == 'text': question = content['text']
                if msg['role'] == 'assistant':
                    for content in msg['content']:
                        if content['type'] == 'text': correct_answer = content['text']
        
        full_img_path = os.path.join(BASE_DIR, image_rel_path)
        if not os.path.exists(full_img_path): return None

        base64_image = encode_image(full_img_path)

        # â˜… Teacherë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸ (Reverse Reasoning)
        system_prompt = (
            "You are an expert in spatial reasoning and 3D perception. "
            "I will provide an image, a question, and the CORRECT answer. "
            "Your task is to generate a 'Chain-of-Thought' explanation that logically leads to that answer.\n"
            "Rules:\n"
            "1. Start by identifying the reference object and the target object in the image.\n"
            "2. Describe their positions relative to each other or the camera.\n"
            "3. Conclude with 'Therefore, the correct option is X.'\n"
            "4. Keep the explanation concise but strictly logical based on visual evidence."
        )
        
        user_content = [
            {"type": "text", "text": f"Question: {question}\nCorrect Answer: {correct_answer}\n\nExplain why this is the correct answer step-by-step."},
            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
        ]

        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_content}
            ],
            max_tokens=300
        )
        
        reasoning = response.choices[0].message.content
        
        # ê²°ê³¼ ì €ì¥ìš© ìƒˆë¡œìš´ ì—”íŠ¸ë¦¬ ìƒì„±
        new_entry = entry.copy()
        # Assistantì˜ ë‹µë³€ì„ Teacherê°€ ìƒì„±í•œ Reasoningìœ¼ë¡œ êµì²´
        new_entry['messages'][1]['content'][0]['text'] = reasoning
        
        return new_entry

    except Exception as e:
        print(f"Error: {e}")
        return None

def main():
    print(f"ğŸš€ Generating Real CoT Data using {MODEL_NAME}...")
    
    with open(INPUT_JSONL, 'r', encoding='utf-8') as f:
        lines = f.readlines()
        
    # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ 10ê°œë§Œ ë¨¼ì € í•´ë³´ê³  ì‹¶ìœ¼ë©´: lines = lines[:10]
    
    results = []
    # ì†ë„ë¥¼ ìœ„í•´ ë³‘ë ¬ ì²˜ë¦¬ (API ì‚¬ìš© ì‹œ) / ë¡œì»¬ GPUë©´ max_workers=1 ì¶”ì²œ
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        futures = [executor.submit(generate_reasoning, json.loads(line)) for line in lines]
        
        for future in tqdm(concurrent.futures.as_completed(futures), total=len(lines)):
            res = future.result()
            if res:
                results.append(res)

    # ì €ì¥
    with open(OUTPUT_JSONL, 'w', encoding='utf-8') as f:
        for item in results:
            f.write(json.dumps(item) + '\n')
            
    print(f"âœ¨ ì™„ë£Œ! ì €ì¥ ê²½ë¡œ: {OUTPUT_JSONL}")

if __name__ == "__main__":
    main()