import torch
from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor
from peft import PeftModel
import os

# ================= ì„¤ì • =================
# 1. í•™ìŠµëœ CoT LoRA ê²½ë¡œ
ADAPTER_DIR = "./checkpoints/mvsm_cot_v1"

# 2. ë² ì´ìŠ¤ ëª¨ë¸ ID
BASE_MODEL_ID = "Qwen/Qwen2.5-VL-3B-Instruct"

# 3. ë³‘í•©ëœ ëª¨ë¸ ì €ì¥ ê²½ë¡œ
OUTPUT_DIR = "./checkpoints/mvsm_cot_merged"
# ========================================

def merge():
    print(f"ğŸš€ Loading Base Model (Offline Mode)...")
    # CPUë¡œ ë¡œë“œí•´ì„œ ë©”ëª¨ë¦¬ ì ˆì•½
    base_model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
        BASE_MODEL_ID,
        torch_dtype=torch.float16,
        device_map="cpu",
        local_files_only=True
    )

    print(f"ğŸš€ Loading CoT LoRA Adapter from: {ADAPTER_DIR}")
    model = PeftModel.from_pretrained(base_model, ADAPTER_DIR)
    
    print("ğŸ”„ Merging LoRA into Base Model...")
    model = model.merge_and_unload()
    
    print(f"ğŸ’¾ Saving merged model to: {OUTPUT_DIR}")
    model.save_pretrained(OUTPUT_DIR)
    
    print("ğŸ’¾ Saving processor...")
    try:
        # ë² ì´ìŠ¤ ëª¨ë¸ì˜ í”„ë¡œì„¸ì„œ ë³µì‚¬
        processor = AutoProcessor.from_pretrained(BASE_MODEL_ID, local_files_only=True)
        processor.save_pretrained(OUTPUT_DIR)
    except Exception as e:
        print(f"âš ï¸ Warning: {e}")
        # ì‹¤íŒ¨ ì‹œ ì–´ëŒ‘í„° í´ë”ì—ì„œ ë³µì‚¬ ì‹œë„
        processor = AutoProcessor.from_pretrained(ADAPTER_DIR, local_files_only=True)
        processor.save_pretrained(OUTPUT_DIR)
    
    print("âœ¨ Merge Complete! ì´ì œ í‰ê°€(Evaluate)ë¥¼ ì¤€ë¹„í•˜ì„¸ìš”.")

if __name__ == "__main__":
    merge()