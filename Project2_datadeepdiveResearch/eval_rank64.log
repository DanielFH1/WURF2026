/nas_data2/seungwoo/2/miniconda3/envs/viewspatial/lib/python3.10/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
`torch_dtype` is deprecated! Use `dtype` instead!
Loading Qwen2.5/MVSM model from: ./checkpoints/mvsm_lora_64_merged
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.63s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
The tokenizer you are loading from './checkpoints/mvsm_lora_64_merged' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.
Model Qwen2.5-VL series:mvsm_lora_64_merged is running!
Evaluating on: data_train/test_hidden.json
  0%|          | 0/858 [00:00<?, ?it/s]  0%|          | 1/858 [00:02<30:09,  2.11s/it]  0%|          | 2/858 [00:02<14:46,  1.04s/it]  0%|          | 3/858 [00:02<09:28,  1.51it/s]  0%|          | 4/858 [00:02<06:49,  2.09it/s]  1%|          | 5/858 [00:03<05:27,  2.61it/s]  1%|          | 6/858 [00:03<04:47,  2.96it/s]  1%|          | 7/858 [00:03<04:18,  3.30it/s]  1%|          | 8/858 [00:03<03:53,  3.64it/s]  1%|          | 9/858 [00:06<14:16,  1.01s/it]  1%|          | 10/858 [00:07<16:08,  1.14s/it]  1%|▏         | 11/858 [00:08<12:15,  1.15it/s]  1%|▏         | 12/858 [00:08<09:33,  1.47it/s]  2%|▏         | 13/858 [00:08<07:40,  1.83it/s]Error on item 0: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 561.62 MiB is free. Process 3432158 has 46.19 GiB memory in use. Including non-PyTorch memory, this process has 626.00 MiB memory in use. Of the allocated memory 111.49 MiB is allocated by PyTorch, and 22.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 1: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 633.62 MiB is free. Process 3432158 has 46.19 GiB memory in use. Including non-PyTorch memory, this process has 554.00 MiB memory in use. Of the allocated memory 45.95 MiB is allocated by PyTorch, and 16.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 2: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 633.62 MiB is free. Process 3432158 has 46.19 GiB memory in use. Including non-PyTorch memory, this process has 554.00 MiB memory in use. Of the allocated memory 45.95 MiB is allocated by PyTorch, and 16.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 3: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 633.62 MiB is free. Process 3432158 has 46.19 GiB memory in use. Including non-PyTorch memory, this process has 554.00 MiB memory in use. Of the allocated memory 45.95 MiB is allocated by PyTorch, and 16.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 4: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 633.62 MiB is free. Process 3432158 has 46.19 GiB memory in use. Including non-PyTorch memory, this process has 554.00 MiB memory in use. Of the allocated memory 45.95 MiB is allocated by PyTorch, and 16.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 5: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 633.62 MiB is free. Process 3432158 has 46.19 GiB memory in use. Including non-PyTorch memory, this process has 554.00 MiB memory in use. Of the allocated memory 45.95 MiB is allocated by PyTorch, and 16.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 6: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 633.62 MiB is free. Process 3432158 has 46.19 GiB memory in use. Including non-PyTorch memory, this process has 554.00 MiB memory in use. Of the allocated memory 45.95 MiB is allocated by PyTorch, and 16.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 7: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 627.62 MiB is free. Process 3432158 has 46.20 GiB memory in use. Including non-PyTorch memory, this process has 554.00 MiB memory in use. Of the allocated memory 45.95 MiB is allocated by PyTorch, and 16.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 8: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 543.62 MiB is free. Process 3432158 has 46.13 GiB memory in use. Including non-PyTorch memory, this process has 706.00 MiB memory in use. Of the allocated memory 192.16 MiB is allocated by PyTorch, and 21.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 9: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 543.62 MiB is free. Process 3432158 has 46.13 GiB memory in use. Including non-PyTorch memory, this process has 706.00 MiB memory in use. Of the allocated memory 121.57 MiB is allocated by PyTorch, and 92.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 10: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 695.62 MiB is free. Process 3432158 has 46.13 GiB memory in use. Including non-PyTorch memory, this process has 554.00 MiB memory in use. Of the allocated memory 45.95 MiB is allocated by PyTorch, and 16.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 11: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 695.62 MiB is free. Process 3432158 has 46.13 GiB memory in use. Including non-PyTorch memory, this process has 554.00 MiB memory in use. Of the allocated memory 45.95 MiB is allocated by PyTorch, and 16.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 12: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 695.62 MiB is free. Process 3432158 has 46.13 GiB memory in use. Including non-PyTorch memory, this process has 554.00 MiB memory in use. Of the allocated memory 45.95 MiB is allocated by PyTorch, and 16.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
  2%|▏         | 14/858 [00:41<2:26:56, 10.45s/it]  2%|▏         | 15/858 [02:30<9:23:16, 40.09s/it]  2%|▏         | 16/858 [02:39<7:09:53, 30.63s/it]  2%|▏         | 17/858 [02:39<5:01:20, 21.50s/it]  2%|▏         | 18/858 [02:39<3:31:38, 15.12s/it]  2%|▏         | 19/858 [02:40<2:28:52, 10.65s/it]  2%|▏         | 20/858 [02:40<1:44:57,  7.52s/it]  2%|▏         | 21/858 [02:40<1:14:13,  5.32s/it]  3%|▎         | 22/858 [02:40<52:54,  3.80s/it]    3%|▎         | 23/858 [02:40<37:58,  2.73s/it]  3%|▎         | 24/858 [02:41<27:20,  1.97s/it]  3%|▎         | 25/858 [02:41<20:05,  1.45s/it]  3%|▎         | 26/858 [02:41<14:52,  1.07s/it]  3%|▎         | 27/858 [02:41<11:18,  1.23it/s]Error on item 13: CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 175.62 MiB is free. Process 3432158 has 45.83 GiB memory in use. Including non-PyTorch memory, this process has 1.35 GiB memory in use. Of the allocated memory 818.22 MiB is allocated by PyTorch, and 51.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 15: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 507.62 MiB is free. Process 3432158 has 46.28 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 68.52 MiB is allocated by PyTorch, and 11.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 16: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 485.62 MiB is free. Process 3432158 has 46.26 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 17: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 725.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 18: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 725.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 19: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 725.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 20: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 725.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 21: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 725.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 22: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 725.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 23: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 725.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 24: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 725.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 25: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 725.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 26: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 725.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
  3%|▎         | 28/858 [02:42<08:49,  1.57it/s]  3%|▎         | 29/858 [02:56<1:05:49,  4.76s/it]  3%|▎         | 30/858 [03:00<1:04:44,  4.69s/it]  4%|▎         | 31/858 [03:01<46:13,  3.35s/it]    4%|▎         | 32/858 [03:01<33:16,  2.42s/it]  4%|▍         | 33/858 [03:01<24:30,  1.78s/it]  4%|▍         | 34/858 [03:01<18:04,  1.32s/it]  4%|▍         | 35/858 [03:02<13:32,  1.01it/s]  4%|▍         | 36/858 [03:02<10:26,  1.31it/s]  4%|▍         | 37/858 [03:02<08:16,  1.65it/s]  4%|▍         | 38/858 [03:02<06:35,  2.07it/s]  5%|▍         | 39/858 [03:03<05:41,  2.40it/s]  5%|▍         | 40/858 [03:03<07:19,  1.86it/s]  5%|▍         | 41/858 [03:04<05:58,  2.28it/s]  5%|▍         | 42/858 [03:11<35:25,  2.61s/it]Error on item 27: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 725.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 29: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 715.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 588.00 MiB memory in use. Of the allocated memory 68.80 MiB is allocated by PyTorch, and 9.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 30: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 731.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 31: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 731.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 32: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 719.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 584.00 MiB memory in use. Of the allocated memory 60.11 MiB is allocated by PyTorch, and 13.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 33: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 731.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 34: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 731.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 35: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 731.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 36: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 731.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 37: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 731.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 38: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 731.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 39: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 681.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 614.00 MiB memory in use. Of the allocated memory 90.37 MiB is allocated by PyTorch, and 13.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 40: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 723.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
  5%|▌         | 43/858 [03:16<43:33,  3.21s/it]  5%|▌         | 44/858 [03:24<1:02:34,  4.61s/it]  5%|▌         | 45/858 [03:33<1:22:08,  6.06s/it]  5%|▌         | 46/858 [03:35<1:05:17,  4.82s/it]  5%|▌         | 47/858 [03:35<46:40,  3.45s/it]    6%|▌         | 48/858 [03:36<33:34,  2.49s/it]  6%|▌         | 49/858 [03:36<24:21,  1.81s/it]  6%|▌         | 50/858 [03:38<24:37,  1.83s/it]  6%|▌         | 51/858 [03:38<18:13,  1.35s/it]  6%|▌         | 52/858 [03:49<57:00,  4.24s/it]  6%|▌         | 53/858 [03:57<1:11:31,  5.33s/it]  6%|▋         | 54/858 [03:57<51:02,  3.81s/it]    6%|▋         | 55/858 [03:57<36:40,  2.74s/it]  7%|▋         | 56/858 [03:58<27:54,  2.09s/it]  7%|▋         | 57/858 [03:58<20:32,  1.54s/it]  7%|▋         | 58/858 [03:58<15:13,  1.14s/it]Error on item 42: CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 277.62 MiB is free. Process 3432158 has 45.49 GiB memory in use. Including non-PyTorch memory, this process has 1.59 GiB memory in use. Of the allocated memory 981.77 MiB is allocated by PyTorch, and 136.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 45: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 187.62 MiB is free. Process 3432158 has 46.58 GiB memory in use. Including non-PyTorch memory, this process has 598.00 MiB memory in use. Of the allocated memory 66.65 MiB is allocated by PyTorch, and 21.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 46: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 213.62 MiB is free. Process 3432158 has 46.58 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 47: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 213.62 MiB is free. Process 3432158 has 46.58 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 48: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 213.62 MiB is free. Process 3432158 has 46.58 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 49: CUDA out of memory. Tried to allocate 116.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 213.62 MiB is free. Process 3432158 has 46.58 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 50.12 MiB is allocated by PyTorch, and 11.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 50: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 213.62 MiB is free. Process 3432158 has 46.58 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 52: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 633.62 MiB is free. Process 3432158 has 46.15 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 69.04 MiB is allocated by PyTorch, and 10.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 53: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 651.62 MiB is free. Process 3432158 has 46.15 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 54: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 651.62 MiB is free. Process 3432158 has 46.15 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 55: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 625.62 MiB is free. Process 3432158 has 46.15 GiB memory in use. Including non-PyTorch memory, this process has 598.00 MiB memory in use. Of the allocated memory 76.12 MiB is allocated by PyTorch, and 11.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 56: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 651.62 MiB is free. Process 3432158 has 46.15 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 57: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 651.62 MiB is free. Process 3432158 has 46.15 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
  7%|▋         | 59/858 [03:59<11:37,  1.15it/s]  7%|▋         | 60/858 [04:10<53:05,  3.99s/it]  7%|▋         | 61/858 [04:10<38:11,  2.88s/it]  7%|▋         | 62/858 [04:10<27:43,  2.09s/it]  7%|▋         | 63/858 [04:11<20:11,  1.52s/it]  7%|▋         | 64/858 [04:11<16:49,  1.27s/it]  8%|▊         | 65/858 [04:12<12:42,  1.04it/s]  8%|▊         | 66/858 [04:12<09:34,  1.38it/s]  8%|▊         | 67/858 [04:12<07:34,  1.74it/s]  8%|▊         | 68/858 [04:12<06:02,  2.18it/s]  8%|▊         | 69/858 [04:12<05:01,  2.62it/s]  8%|▊         | 70/858 [04:26<57:50,  4.40s/it]  8%|▊         | 71/858 [04:31<58:55,  4.49s/it]  8%|▊         | 72/858 [04:31<42:02,  3.21s/it]Error on item 58: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 651.62 MiB is free. Process 3432158 has 46.15 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 59: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 411.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 890.00 MiB memory in use. Of the allocated memory 309.24 MiB is allocated by PyTorch, and 70.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 60: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 729.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 61: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 729.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 62: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 729.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 63: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 693.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 608.00 MiB memory in use. Of the allocated memory 86.15 MiB is allocated by PyTorch, and 11.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 64: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 729.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 65: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 729.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 66: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 729.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 67: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 729.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 68: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 729.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 70: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 181.62 MiB is free. Process 3432158 has 46.60 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 68.91 MiB is allocated by PyTorch, and 11.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 71: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 199.62 MiB is free. Process 3432158 has 46.60 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
  9%|▊         | 73/858 [04:34<40:33,  3.10s/it]  9%|▊         | 74/858 [04:34<30:33,  2.34s/it]  9%|▊         | 75/858 [04:35<23:07,  1.77s/it]  9%|▉         | 76/858 [04:35<17:39,  1.36s/it]  9%|▉         | 77/858 [04:47<59:04,  4.54s/it]  9%|▉         | 78/858 [04:52<1:01:48,  4.75s/it]  9%|▉         | 79/858 [04:55<54:41,  4.21s/it]    9%|▉         | 80/858 [04:57<42:29,  3.28s/it]  9%|▉         | 81/858 [05:05<1:03:54,  4.94s/it] 10%|▉         | 82/858 [05:13<1:16:03,  5.88s/it] 10%|▉         | 83/858 [05:21<1:23:05,  6.43s/it] 10%|▉         | 84/858 [05:29<1:28:37,  6.87s/it] 10%|▉         | 85/858 [05:38<1:36:09,  7.46s/it] 10%|█         | 86/858 [05:43<1:25:31,  6.65s/it] 10%|█         | 87/858 [05:54<1:43:26,  8.05s/it] 10%|█         | 88/858 [05:57<1:24:41,  6.60s/it] 10%|█         | 89/858 [05:57<1:00:01,  4.68s/it] 10%|█         | 90/858 [05:58<45:19,  3.54s/it]   11%|█         | 91/858 [06:10<1:17:00,  6.02s/it] 11%|█         | 92/858 [06:18<1:23:40,  6.55s/it]Error on item 72: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 741.62 MiB is free. Process 3432158 has 46.05 GiB memory in use. Including non-PyTorch memory, this process has 588.00 MiB memory in use. Of the allocated memory 68.55 MiB is allocated by PyTorch, and 9.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 73: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 161.62 MiB is free. Process 3432158 has 46.05 GiB memory in use. Including non-PyTorch memory, this process has 1.14 GiB memory in use. Of the allocated memory 80.77 MiB is allocated by PyTorch, and 577.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 74: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 163.62 MiB is free. Process 3432158 has 46.05 GiB memory in use. Including non-PyTorch memory, this process has 1.14 GiB memory in use. Of the allocated memory 70.20 MiB is allocated by PyTorch, and 585.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 75: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 161.62 MiB is free. Process 3432158 has 46.05 GiB memory in use. Including non-PyTorch memory, this process has 1.14 GiB memory in use. Of the allocated memory 62.17 MiB is allocated by PyTorch, and 593.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 77: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 471.62 MiB is free. Process 3432158 has 46.31 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 69.11 MiB is allocated by PyTorch, and 10.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 78: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 753.62 MiB is free. Process 3432158 has 46.04 GiB memory in use. Including non-PyTorch memory, this process has 588.00 MiB memory in use. Of the allocated memory 68.59 MiB is allocated by PyTorch, and 9.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 79: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 699.62 MiB is free. Process 3432158 has 46.05 GiB memory in use. Including non-PyTorch memory, this process has 634.00 MiB memory in use. Of the allocated memory 110.53 MiB is allocated by PyTorch, and 13.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 83: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 753.62 MiB is free. Process 3432158 has 46.04 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 68.94 MiB is allocated by PyTorch, and 11.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 85: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 745.62 MiB is free. Process 3432158 has 46.04 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 69.11 MiB is allocated by PyTorch, and 10.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 87: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 627.62 MiB is free. Process 3432158 has 46.16 GiB memory in use. Including non-PyTorch memory, this process has 588.00 MiB memory in use. Of the allocated memory 68.59 MiB is allocated by PyTorch, and 9.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 88: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 643.62 MiB is free. Process 3432158 has 46.16 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 89: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 597.62 MiB is free. Process 3432158 has 46.16 GiB memory in use. Including non-PyTorch memory, this process has 618.00 MiB memory in use. Of the allocated memory 96.19 MiB is allocated by PyTorch, and 11.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 90: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 201.62 MiB is free. Process 3432158 has 46.18 GiB memory in use. Including non-PyTorch memory, this process has 994.00 MiB memory in use. Of the allocated memory 400.04 MiB is allocated by PyTorch, and 83.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 11%|█         | 93/858 [06:34<2:00:35,  9.46s/it] 11%|█         | 94/858 [06:34<1:25:14,  6.69s/it] 11%|█         | 95/858 [06:35<1:00:26,  4.75s/it] 11%|█         | 96/858 [06:35<43:10,  3.40s/it]   11%|█▏        | 97/858 [06:35<30:59,  2.44s/it] 11%|█▏        | 98/858 [06:35<22:27,  1.77s/it] 12%|█▏        | 99/858 [06:36<19:05,  1.51s/it] 12%|█▏        | 100/858 [06:36<14:17,  1.13s/it] 12%|█▏        | 101/858 [06:39<21:33,  1.71s/it] 12%|█▏        | 102/858 [06:40<15:58,  1.27s/it] 12%|█▏        | 103/858 [06:40<11:58,  1.05it/s] 12%|█▏        | 104/858 [06:40<09:21,  1.34it/s] 12%|█▏        | 105/858 [06:40<07:26,  1.69it/s]Error on item 92: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 177.62 MiB is free. Process 3432158 has 46.12 GiB memory in use. Including non-PyTorch memory, this process has 1.06 GiB memory in use. Of the allocated memory 443.69 MiB is allocated by PyTorch, and 128.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 93: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 687.62 MiB is free. Process 3432158 has 46.12 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 94: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 687.62 MiB is free. Process 3432158 has 46.12 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 95: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 687.62 MiB is free. Process 3432158 has 46.12 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 96: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 687.62 MiB is free. Process 3432158 has 46.12 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 97: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 687.62 MiB is free. Process 3432158 has 46.12 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 98: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 641.62 MiB is free. Process 3432158 has 46.12 GiB memory in use. Including non-PyTorch memory, this process has 618.00 MiB memory in use. Of the allocated memory 96.19 MiB is allocated by PyTorch, and 11.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 99: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 681.62 MiB is free. Process 3432158 has 46.12 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 100: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 687.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 588.00 MiB memory in use. Of the allocated memory 68.43 MiB is allocated by PyTorch, and 9.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 101: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 703.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 102: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 703.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 103: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 703.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 104: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 703.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 12%|█▏        | 106/858 [06:41<06:06,  2.05it/s] 12%|█▏        | 107/858 [06:41<05:02,  2.48it/s] 13%|█▎        | 108/858 [06:42<06:05,  2.05it/s] 13%|█▎        | 109/858 [06:42<05:08,  2.43it/s] 13%|█▎        | 110/858 [06:42<04:23,  2.84it/s] 13%|█▎        | 111/858 [06:54<46:40,  3.75s/it] 13%|█▎        | 112/858 [07:03<1:05:47,  5.29s/it] 13%|█▎        | 113/858 [07:05<53:30,  4.31s/it]   13%|█▎        | 114/858 [07:05<38:10,  3.08s/it] 13%|█▎        | 115/858 [07:05<27:31,  2.22s/it] 14%|█▎        | 116/858 [07:05<20:00,  1.62s/it] 14%|█▎        | 117/858 [07:05<14:42,  1.19s/it] 14%|█▍        | 118/858 [07:16<48:49,  3.96s/it] 14%|█▍        | 119/858 [07:22<57:43,  4.69s/it]Error on item 105: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 703.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 106: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 703.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 107: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 667.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 608.00 MiB memory in use. Of the allocated memory 86.15 MiB is allocated by PyTorch, and 11.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 108: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 703.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 109: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 703.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 110: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 745.62 MiB is free. Process 3432158 has 45.50 GiB memory in use. Including non-PyTorch memory, this process has 1.12 GiB memory in use. Of the allocated memory 507.01 MiB is allocated by PyTorch, and 126.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 111: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 519.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 800.00 MiB memory in use. Of the allocated memory 234.15 MiB is allocated by PyTorch, and 55.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 112: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 605.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 714.00 MiB memory in use. Of the allocated memory 171.03 MiB is allocated by PyTorch, and 32.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 113: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 747.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 114: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 747.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 115: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 739.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 116: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 739.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 118: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 255.62 MiB is free. Process 3432158 has 46.52 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 68.97 MiB is allocated by PyTorch, and 11.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 14%|█▍        | 120/858 [07:22<41:13,  3.35s/it] 14%|█▍        | 121/858 [07:23<30:01,  2.44s/it] 14%|█▍        | 122/858 [07:23<21:48,  1.78s/it] 14%|█▍        | 123/858 [07:23<15:57,  1.30s/it] 14%|█▍        | 124/858 [07:23<11:59,  1.02it/s] 15%|█▍        | 125/858 [07:24<09:10,  1.33it/s] 15%|█▍        | 126/858 [07:24<07:01,  1.74it/s] 15%|█▍        | 127/858 [07:24<05:42,  2.14it/s] 15%|█▍        | 128/858 [07:24<04:49,  2.52it/s] 15%|█▌        | 129/858 [07:24<04:06,  2.96it/s] 15%|█▌        | 130/858 [07:25<03:42,  3.27it/s] 15%|█▌        | 131/858 [07:25<03:18,  3.65it/s] 15%|█▌        | 132/858 [07:25<03:02,  3.99it/s]Error on item 119: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 273.62 MiB is free. Process 3432158 has 46.52 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 120: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 261.62 MiB is free. Process 3432158 has 46.52 GiB memory in use. Including non-PyTorch memory, this process has 584.00 MiB memory in use. Of the allocated memory 60.11 MiB is allocated by PyTorch, and 13.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 121: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 273.62 MiB is free. Process 3432158 has 46.52 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 122: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 273.62 MiB is free. Process 3432158 has 46.52 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 123: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 273.62 MiB is free. Process 3432158 has 46.52 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 124: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 273.62 MiB is free. Process 3432158 has 46.52 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 125: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 273.62 MiB is free. Process 3432158 has 46.52 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 126: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 273.62 MiB is free. Process 3432158 has 46.52 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 127: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 273.62 MiB is free. Process 3432158 has 46.52 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 128: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 273.62 MiB is free. Process 3432158 has 46.52 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 129: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 273.62 MiB is free. Process 3432158 has 46.52 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 130: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 273.62 MiB is free. Process 3432158 has 46.52 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 131: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 267.62 MiB is free. Process 3432158 has 46.53 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 16%|█▌        | 133/858 [07:25<02:49,  4.27it/s] 16%|█▌        | 134/858 [07:29<15:36,  1.29s/it] 16%|█▌        | 135/858 [07:29<11:43,  1.03it/s] 16%|█▌        | 136/858 [07:31<14:16,  1.19s/it] 16%|█▌        | 137/858 [07:31<10:51,  1.11it/s] 16%|█▌        | 138/858 [07:31<08:20,  1.44it/s] 16%|█▌        | 139/858 [07:44<50:54,  4.25s/it] 16%|█▋        | 140/858 [07:52<1:05:41,  5.49s/it] 16%|█▋        | 141/858 [08:01<1:17:29,  6.48s/it] 17%|█▋        | 142/858 [08:02<58:01,  4.86s/it]   17%|█▋        | 143/858 [08:02<41:21,  3.47s/it] 17%|█▋        | 144/858 [08:09<53:24,  4.49s/it] 17%|█▋        | 145/858 [08:10<38:17,  3.22s/it] 17%|█▋        | 146/858 [08:18<55:37,  4.69s/it] 17%|█▋        | 147/858 [08:27<1:10:59,  5.99s/it] 17%|█▋        | 148/858 [08:28<53:29,  4.52s/it]  Error on item 132: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 267.62 MiB is free. Process 3432158 has 46.53 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 133: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 579.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 588.00 MiB memory in use. Of the allocated memory 68.47 MiB is allocated by PyTorch, and 9.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 134: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 595.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 135: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 489.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 678.00 MiB memory in use. Of the allocated memory 156.39 MiB is allocated by PyTorch, and 11.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 136: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 595.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 137: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 589.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 141: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 391.62 MiB is free. Process 3432158 has 46.35 GiB memory in use. Including non-PyTorch memory, this process has 634.00 MiB memory in use. Of the allocated memory 110.53 MiB is allocated by PyTorch, and 13.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 142: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 533.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 143: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 659.62 MiB is free. Process 3432158 has 46.13 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 68.90 MiB is allocated by PyTorch, and 11.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 144: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 437.62 MiB is free. Process 3432158 has 46.29 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 145: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 217.62 MiB is free. Process 3432158 has 45.77 GiB memory in use. Including non-PyTorch memory, this process has 1.37 GiB memory in use. Of the allocated memory 359.96 MiB is allocated by PyTorch, and 528.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 146: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 583.62 MiB is free. Process 3432158 has 46.05 GiB memory in use. Including non-PyTorch memory, this process has 744.00 MiB memory in use. Of the allocated memory 128.73 MiB is allocated by PyTorch, and 105.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 147: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 659.62 MiB is free. Process 3432158 has 46.05 GiB memory in use. Including non-PyTorch memory, this process has 668.00 MiB memory in use. Of the allocated memory 110.53 MiB is allocated by PyTorch, and 47.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 17%|█▋        | 149/858 [08:28<38:46,  3.28s/it] 17%|█▋        | 150/858 [08:29<28:33,  2.42s/it] 18%|█▊        | 151/858 [08:37<50:56,  4.32s/it] 18%|█▊        | 152/858 [08:46<1:07:12,  5.71s/it] 18%|█▊        | 153/858 [08:55<1:16:13,  6.49s/it] 18%|█▊        | 154/858 [09:01<1:16:37,  6.53s/it] 18%|█▊        | 155/858 [09:01<54:28,  4.65s/it]   18%|█▊        | 156/858 [09:02<38:45,  3.31s/it] 18%|█▊        | 157/858 [09:03<31:11,  2.67s/it] 18%|█▊        | 158/858 [09:03<22:30,  1.93s/it] 19%|█▊        | 159/858 [09:03<16:30,  1.42s/it] 19%|█▊        | 160/858 [09:20<1:10:54,  6.10s/it] 19%|█▉        | 161/858 [09:22<55:08,  4.75s/it]   19%|█▉        | 162/858 [09:29<1:02:09,  5.36s/it] 19%|█▉        | 163/858 [09:37<1:12:39,  6.27s/it] 19%|█▉        | 164/858 [09:37<51:46,  4.48s/it]   19%|█▉        | 165/858 [09:38<38:45,  3.36s/it] 19%|█▉        | 166/858 [09:52<1:15:08,  6.52s/it] 19%|█▉        | 167/858 [09:58<1:12:28,  6.29s/it]Error on item 148: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 161.62 MiB is free. Process 3432158 has 46.05 GiB memory in use. Including non-PyTorch memory, this process has 1.14 GiB memory in use. Of the allocated memory 62.19 MiB is allocated by PyTorch, and 593.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 149: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 161.62 MiB is free. Process 3432158 has 46.05 GiB memory in use. Including non-PyTorch memory, this process has 1.14 GiB memory in use. Of the allocated memory 62.18 MiB is allocated by PyTorch, and 593.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 153: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 667.62 MiB is free. Process 3432158 has 46.12 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 68.83 MiB is allocated by PyTorch, and 11.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 154: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 685.62 MiB is free. Process 3432158 has 46.12 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 155: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 685.62 MiB is free. Process 3432158 has 46.12 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 156: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 609.62 MiB is free. Process 3432158 has 46.12 GiB memory in use. Including non-PyTorch memory, this process has 648.00 MiB memory in use. Of the allocated memory 126.29 MiB is allocated by PyTorch, and 11.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 157: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 685.62 MiB is free. Process 3432158 has 46.12 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 158: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 685.62 MiB is free. Process 3432158 has 46.12 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 160: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 695.62 MiB is free. Process 3432158 has 45.90 GiB memory in use. Including non-PyTorch memory, this process has 708.00 MiB memory in use. Of the allocated memory 145.82 MiB is allocated by PyTorch, and 52.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 162: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 607.62 MiB is free. Process 3432158 has 46.18 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 69.01 MiB is allocated by PyTorch, and 10.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 163: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 613.62 MiB is free. Process 3432158 has 46.18 GiB memory in use. Including non-PyTorch memory, this process has 584.00 MiB memory in use. Of the allocated memory 60.11 MiB is allocated by PyTorch, and 13.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 164: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 589.62 MiB is free. Process 3432158 has 46.18 GiB memory in use. Including non-PyTorch memory, this process has 608.00 MiB memory in use. Of the allocated memory 86.15 MiB is allocated by PyTorch, and 11.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 166: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 733.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 68.94 MiB is allocated by PyTorch, and 11.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 20%|█▉        | 168/858 [09:58<51:27,  4.47s/it]   20%|█▉        | 169/858 [09:58<36:36,  3.19s/it] 20%|█▉        | 170/858 [09:59<28:39,  2.50s/it] 20%|█▉        | 171/858 [09:59<20:46,  1.81s/it] 20%|██        | 172/858 [10:00<16:29,  1.44s/it] 20%|██        | 173/858 [10:00<12:23,  1.09s/it] 20%|██        | 174/858 [10:00<09:28,  1.20it/s] 20%|██        | 175/858 [10:01<07:23,  1.54it/s] 21%|██        | 176/858 [10:01<05:43,  1.99it/s] 21%|██        | 177/858 [10:09<32:43,  2.88s/it] 21%|██        | 178/858 [10:18<53:51,  4.75s/it] 21%|██        | 179/858 [10:19<38:30,  3.40s/it] 21%|██        | 180/858 [10:21<35:25,  3.14s/it] 21%|██        | 181/858 [10:21<25:20,  2.25s/it] 21%|██        | 182/858 [10:33<58:16,  5.17s/it] 21%|██▏       | 183/858 [10:44<1:17:00,  6.85s/it]Error on item 167: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 751.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 168: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 751.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 169: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 705.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 618.00 MiB memory in use. Of the allocated memory 96.19 MiB is allocated by PyTorch, and 11.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 170: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 751.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 171: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 725.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 598.00 MiB memory in use. Of the allocated memory 76.12 MiB is allocated by PyTorch, and 11.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 172: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 751.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 173: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 751.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 174: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 743.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 175: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 743.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 177: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 699.62 MiB is free. Process 3432158 has 46.09 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 69.01 MiB is allocated by PyTorch, and 10.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 178: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 717.62 MiB is free. Process 3432158 has 46.09 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 179: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 549.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 734.00 MiB memory in use. Of the allocated memory 211.36 MiB is allocated by PyTorch, and 12.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 180: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 711.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 21%|██▏       | 184/858 [10:44<54:32,  4.86s/it]   22%|██▏       | 185/858 [10:44<38:52,  3.47s/it] 22%|██▏       | 186/858 [10:45<28:00,  2.50s/it] 22%|██▏       | 187/858 [10:46<25:22,  2.27s/it] 22%|██▏       | 188/858 [10:47<18:30,  1.66s/it] 22%|██▏       | 189/858 [10:47<13:32,  1.21s/it] 22%|██▏       | 190/858 [10:47<10:15,  1.09it/s] 22%|██▏       | 191/858 [10:47<07:54,  1.40it/s] 22%|██▏       | 192/858 [10:47<06:12,  1.79it/s] 22%|██▏       | 193/858 [11:00<46:02,  4.15s/it] 23%|██▎       | 194/858 [11:06<53:04,  4.80s/it] 23%|██▎       | 195/858 [11:06<37:48,  3.42s/it] 23%|██▎       | 196/858 [11:07<27:08,  2.46s/it] 23%|██▎       | 197/858 [11:07<19:34,  1.78s/it]Error on item 183: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 441.62 MiB is free. Process 3432158 has 46.36 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 184: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 441.62 MiB is free. Process 3432158 has 46.36 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 185: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 441.62 MiB is free. Process 3432158 has 46.36 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 186: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 339.62 MiB is free. Process 3432158 has 46.36 GiB memory in use. Including non-PyTorch memory, this process has 674.00 MiB memory in use. Of the allocated memory 150.87 MiB is allocated by PyTorch, and 13.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 187: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 441.62 MiB is free. Process 3432158 has 46.36 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 188: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 441.62 MiB is free. Process 3432158 has 46.36 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 189: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 441.62 MiB is free. Process 3432158 has 46.36 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 190: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 437.62 MiB is free. Process 3432158 has 46.36 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 191: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 235.62 MiB is free. Process 3432158 has 46.48 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 193: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 629.62 MiB is free. Process 3432158 has 46.13 GiB memory in use. Including non-PyTorch memory, this process has 614.00 MiB memory in use. Of the allocated memory 83.85 MiB is allocated by PyTorch, and 20.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 194: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 671.62 MiB is free. Process 3432158 has 46.13 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 195: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 671.62 MiB is free. Process 3432158 has 46.13 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 196: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 671.62 MiB is free. Process 3432158 has 46.13 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 23%|██▎       | 198/858 [11:07<14:26,  1.31s/it] 23%|██▎       | 199/858 [11:07<10:45,  1.02it/s] 23%|██▎       | 200/858 [11:17<38:49,  3.54s/it] 23%|██▎       | 201/858 [11:17<27:49,  2.54s/it] 24%|██▎       | 202/858 [11:18<21:42,  1.99s/it] 24%|██▎       | 203/858 [11:18<15:54,  1.46s/it] 24%|██▍       | 204/858 [11:18<12:03,  1.11s/it] 24%|██▍       | 205/858 [11:19<09:28,  1.15it/s] 24%|██▍       | 206/858 [11:19<07:30,  1.45it/s] 24%|██▍       | 207/858 [11:19<06:11,  1.75it/s] 24%|██▍       | 208/858 [11:19<05:03,  2.14it/s] 24%|██▍       | 209/858 [11:20<04:39,  2.32it/s] 24%|██▍       | 210/858 [11:20<04:15,  2.53it/s] 25%|██▍       | 211/858 [11:20<03:43,  2.89it/s]Error on item 197: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 671.62 MiB is free. Process 3432158 has 46.13 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 198: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 665.62 MiB is free. Process 3432158 has 46.14 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 200: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 269.62 MiB is free. Process 3432158 has 46.53 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 201: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 233.62 MiB is free. Process 3432158 has 46.53 GiB memory in use. Including non-PyTorch memory, this process has 608.00 MiB memory in use. Of the allocated memory 86.15 MiB is allocated by PyTorch, and 11.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 202: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 269.62 MiB is free. Process 3432158 has 46.53 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 203: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 269.62 MiB is free. Process 3432158 has 46.53 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 204: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 269.62 MiB is free. Process 3432158 has 46.53 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 205: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 269.62 MiB is free. Process 3432158 has 46.53 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 206: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 269.62 MiB is free. Process 3432158 has 46.53 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 207: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 269.62 MiB is free. Process 3432158 has 46.53 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 208: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 253.62 MiB is free. Process 3432158 has 46.53 GiB memory in use. Including non-PyTorch memory, this process has 588.00 MiB memory in use. Of the allocated memory 66.08 MiB is allocated by PyTorch, and 11.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 209: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 253.62 MiB is free. Process 3432158 has 46.53 GiB memory in use. Including non-PyTorch memory, this process has 588.00 MiB memory in use. Of the allocated memory 60.11 MiB is allocated by PyTorch, and 17.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 210: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 263.62 MiB is free. Process 3432158 has 46.53 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 25%|██▍       | 212/858 [11:20<03:09,  3.42it/s] 25%|██▍       | 213/858 [11:32<39:16,  3.65s/it] 25%|██▍       | 214/858 [11:35<37:28,  3.49s/it] 25%|██▌       | 215/858 [11:38<35:52,  3.35s/it] 25%|██▌       | 216/858 [11:40<31:00,  2.90s/it] 25%|██▌       | 217/858 [11:40<22:19,  2.09s/it] 25%|██▌       | 218/858 [11:40<16:20,  1.53s/it] 26%|██▌       | 219/858 [11:41<12:08,  1.14s/it] 26%|██▌       | 220/858 [11:41<09:15,  1.15it/s] 26%|██▌       | 221/858 [11:41<07:17,  1.46it/s] 26%|██▌       | 222/858 [11:48<25:54,  2.44s/it] 26%|██▌       | 223/858 [11:55<41:46,  3.95s/it] 26%|██▌       | 224/858 [11:58<37:45,  3.57s/it] 26%|██▌       | 225/858 [11:58<27:09,  2.57s/it] 26%|██▋       | 226/858 [11:58<19:36,  1.86s/it]Error on item 211: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 263.62 MiB is free. Process 3432158 has 46.53 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 212: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 573.62 MiB is free. Process 3432158 has 45.43 GiB memory in use. Including non-PyTorch memory, this process has 1.36 GiB memory in use. Of the allocated memory 323.41 MiB is allocated by PyTorch, and 558.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 213: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 171.62 MiB is free. Process 3432158 has 46.55 GiB memory in use. Including non-PyTorch memory, this process has 648.00 MiB memory in use. Of the allocated memory 79.89 MiB is allocated by PyTorch, and 58.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 214: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 725.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 584.00 MiB memory in use. Of the allocated memory 68.32 MiB is allocated by PyTorch, and 5.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 215: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 621.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 688.00 MiB memory in use. Of the allocated memory 166.43 MiB is allocated by PyTorch, and 11.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 216: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 737.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 217: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 737.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 218: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 737.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 219: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 737.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 220: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 719.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 584.00 MiB memory in use. Of the allocated memory 60.11 MiB is allocated by PyTorch, and 13.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 223: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 439.62 MiB is free. Process 3432158 has 46.54 GiB memory in use. Including non-PyTorch memory, this process has 588.00 MiB memory in use. Of the allocated memory 68.67 MiB is allocated by PyTorch, and 9.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 224: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 255.62 MiB is free. Process 3432158 has 46.54 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 225: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 255.62 MiB is free. Process 3432158 has 46.54 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 26%|██▋       | 227/858 [12:00<18:03,  1.72s/it] 27%|██▋       | 228/858 [12:00<13:21,  1.27s/it] 27%|██▋       | 229/858 [12:00<09:54,  1.06it/s] 27%|██▋       | 230/858 [12:00<07:36,  1.37it/s] 27%|██▋       | 231/858 [12:00<05:52,  1.78it/s] 27%|██▋       | 232/858 [12:01<04:45,  2.19it/s] 27%|██▋       | 233/858 [12:01<03:56,  2.65it/s] 27%|██▋       | 234/858 [12:01<03:22,  3.08it/s] 27%|██▋       | 235/858 [12:04<12:45,  1.23s/it] 28%|██▊       | 236/858 [12:05<09:35,  1.08it/s] 28%|██▊       | 237/858 [12:06<09:53,  1.05it/s] 28%|██▊       | 238/858 [12:06<07:37,  1.36it/s] 28%|██▊       | 239/858 [12:07<08:36,  1.20it/s]Error on item 226: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 173.62 MiB is free. Process 3432158 has 46.54 GiB memory in use. Including non-PyTorch memory, this process has 654.00 MiB memory in use. Of the allocated memory 130.70 MiB is allocated by PyTorch, and 13.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 227: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 255.62 MiB is free. Process 3432158 has 46.54 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 228: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 255.62 MiB is free. Process 3432158 has 46.54 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 229: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 255.62 MiB is free. Process 3432158 has 46.54 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 230: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 255.62 MiB is free. Process 3432158 has 46.54 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 231: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 255.62 MiB is free. Process 3432158 has 46.54 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 232: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 249.62 MiB is free. Process 3432158 has 46.55 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 233: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 249.62 MiB is free. Process 3432158 has 46.55 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 234: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 589.62 MiB is free. Process 3432158 has 46.20 GiB memory in use. Including non-PyTorch memory, this process has 584.00 MiB memory in use. Of the allocated memory 68.28 MiB is allocated by PyTorch, and 5.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 235: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 601.62 MiB is free. Process 3432158 has 46.20 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 236: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 545.62 MiB is free. Process 3432158 has 46.20 GiB memory in use. Including non-PyTorch memory, this process has 628.00 MiB memory in use. Of the allocated memory 106.22 MiB is allocated by PyTorch, and 11.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 237: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 601.62 MiB is free. Process 3432158 has 46.20 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 238: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 539.62 MiB is free. Process 3432158 has 46.20 GiB memory in use. Including non-PyTorch memory, this process has 634.00 MiB memory in use. Of the allocated memory 110.53 MiB is allocated by PyTorch, and 13.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 28%|██▊       | 240/858 [12:07<06:35,  1.56it/s] 28%|██▊       | 241/858 [12:07<05:13,  1.97it/s] 28%|██▊       | 242/858 [12:17<32:17,  3.14s/it] 28%|██▊       | 243/858 [12:25<48:32,  4.74s/it] 28%|██▊       | 244/858 [12:25<34:29,  3.37s/it] 29%|██▊       | 245/858 [12:25<24:46,  2.42s/it] 29%|██▊       | 246/858 [12:26<17:57,  1.76s/it] 29%|██▉       | 247/858 [12:26<13:15,  1.30s/it] 29%|██▉       | 248/858 [12:26<09:51,  1.03it/s] 29%|██▉       | 249/858 [12:26<07:31,  1.35it/s] 29%|██▉       | 250/858 [12:26<05:56,  1.71it/s] 29%|██▉       | 251/858 [12:27<04:54,  2.06it/s] 29%|██▉       | 252/858 [12:27<04:07,  2.45it/s] 29%|██▉       | 253/858 [12:27<03:35,  2.81it/s]Error on item 239: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 601.62 MiB is free. Process 3432158 has 46.20 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 240: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 597.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 242: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 609.62 MiB is free. Process 3432158 has 46.18 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 68.80 MiB is allocated by PyTorch, and 11.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 243: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 627.62 MiB is free. Process 3432158 has 46.18 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 244: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 627.62 MiB is free. Process 3432158 has 46.18 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 245: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 627.62 MiB is free. Process 3432158 has 46.18 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 246: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 627.62 MiB is free. Process 3432158 has 46.18 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 247: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 627.62 MiB is free. Process 3432158 has 46.18 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 248: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 627.62 MiB is free. Process 3432158 has 46.18 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 249: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 627.62 MiB is free. Process 3432158 has 46.18 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 250: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 627.62 MiB is free. Process 3432158 has 46.18 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 251: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 627.62 MiB is free. Process 3432158 has 46.18 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 252: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 627.62 MiB is free. Process 3432158 has 46.18 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 30%|██▉       | 254/858 [12:27<03:02,  3.30it/s] 30%|██▉       | 255/858 [12:28<02:46,  3.63it/s] 30%|██▉       | 256/858 [12:39<36:04,  3.60s/it] 30%|██▉       | 257/858 [12:49<56:06,  5.60s/it] 30%|███       | 258/858 [12:53<49:42,  4.97s/it] 30%|███       | 259/858 [12:53<35:24,  3.55s/it] 30%|███       | 260/858 [12:53<25:21,  2.54s/it] 30%|███       | 261/858 [12:53<18:17,  1.84s/it] 31%|███       | 262/858 [12:54<13:19,  1.34s/it] 31%|███       | 263/858 [12:54<09:56,  1.00s/it] 31%|███       | 264/858 [12:54<07:40,  1.29it/s] 31%|███       | 265/858 [12:54<06:04,  1.63it/s] 31%|███       | 266/858 [12:54<04:51,  2.03it/s] 31%|███       | 267/858 [12:55<03:58,  2.47it/s]Error on item 253: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 627.62 MiB is free. Process 3432158 has 46.18 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 254: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 627.62 MiB is free. Process 3432158 has 46.18 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 255: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 479.62 MiB is free. Process 3432158 has 45.65 GiB memory in use. Including non-PyTorch memory, this process has 1.23 GiB memory in use. Of the allocated memory 265.48 MiB is allocated by PyTorch, and 482.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 257: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 421.62 MiB is free. Process 3432158 has 46.37 GiB memory in use. Including non-PyTorch memory, this process has 584.00 MiB memory in use. Of the allocated memory 67.92 MiB is allocated by PyTorch, and 6.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 258: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 193.62 MiB is free. Process 3432158 has 46.60 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 259: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 193.62 MiB is free. Process 3432158 has 46.60 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 260: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 193.62 MiB is free. Process 3432158 has 46.60 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 261: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 193.62 MiB is free. Process 3432158 has 46.60 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 262: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 193.62 MiB is free. Process 3432158 has 46.60 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 263: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 193.62 MiB is free. Process 3432158 has 46.60 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 264: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 193.62 MiB is free. Process 3432158 has 46.60 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 265: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 193.62 MiB is free. Process 3432158 has 46.60 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 266: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 193.62 MiB is free. Process 3432158 has 46.60 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 31%|███       | 268/858 [12:55<03:26,  2.86it/s] 31%|███▏      | 269/858 [12:55<02:58,  3.29it/s] 31%|███▏      | 270/858 [12:55<02:35,  3.78it/s] 32%|███▏      | 271/858 [12:55<02:20,  4.16it/s] 32%|███▏      | 272/858 [12:56<02:09,  4.51it/s] 32%|███▏      | 273/858 [12:56<02:05,  4.68it/s] 32%|███▏      | 274/858 [12:56<01:58,  4.93it/s] 32%|███▏      | 275/858 [12:56<02:01,  4.80it/s] 32%|███▏      | 276/858 [13:00<12:48,  1.32s/it] 32%|███▏      | 277/858 [13:00<10:10,  1.05s/it] 32%|███▏      | 278/858 [13:01<07:47,  1.24it/s] 33%|███▎      | 279/858 [13:01<06:00,  1.61it/s] 33%|███▎      | 280/858 [13:02<06:44,  1.43it/s]Error on item 267: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 193.62 MiB is free. Process 3432158 has 46.60 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 268: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 193.62 MiB is free. Process 3432158 has 46.60 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 269: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 193.62 MiB is free. Process 3432158 has 46.60 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 270: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 193.62 MiB is free. Process 3432158 has 46.60 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 271: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 193.62 MiB is free. Process 3432158 has 46.60 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 272: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 193.62 MiB is free. Process 3432158 has 46.60 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 273: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 187.62 MiB is free. Process 3432158 has 46.61 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 274: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 285.62 MiB is free. Process 3432158 has 46.43 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 275: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 515.62 MiB is free. Process 3432158 has 46.27 GiB memory in use. Including non-PyTorch memory, this process has 588.00 MiB memory in use. Of the allocated memory 68.47 MiB is allocated by PyTorch, and 9.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 276: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 515.62 MiB is free. Process 3432158 has 46.27 GiB memory in use. Including non-PyTorch memory, this process has 588.00 MiB memory in use. Of the allocated memory 66.08 MiB is allocated by PyTorch, and 11.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 277: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 531.62 MiB is free. Process 3432158 has 46.27 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 278: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 531.62 MiB is free. Process 3432158 has 46.27 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 279: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 475.62 MiB is free. Process 3432158 has 46.27 GiB memory in use. Including non-PyTorch memory, this process has 628.00 MiB memory in use. Of the allocated memory 106.22 MiB is allocated by PyTorch, and 11.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 33%|███▎      | 281/858 [13:02<05:19,  1.80it/s] 33%|███▎      | 282/858 [13:02<04:18,  2.23it/s] 33%|███▎      | 283/858 [13:14<35:48,  3.74s/it] 33%|███▎      | 284/858 [13:21<46:20,  4.84s/it] 33%|███▎      | 285/858 [13:21<33:02,  3.46s/it] 33%|███▎      | 286/858 [13:22<23:43,  2.49s/it] 33%|███▎      | 287/858 [13:22<17:14,  1.81s/it] 34%|███▎      | 288/858 [13:22<12:37,  1.33s/it] 34%|███▎      | 289/858 [13:22<09:30,  1.00s/it] 34%|███▍      | 290/858 [13:22<07:11,  1.32it/s] 34%|███▍      | 291/858 [13:23<05:33,  1.70it/s] 34%|███▍      | 292/858 [13:23<04:31,  2.08it/s] 34%|███▍      | 293/858 [13:23<03:41,  2.56it/s] 34%|███▍      | 294/858 [13:23<03:06,  3.02it/s]Error on item 280: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 531.62 MiB is free. Process 3432158 has 46.27 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 281: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 525.62 MiB is free. Process 3432158 has 46.28 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 283: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 645.62 MiB is free. Process 3432158 has 46.14 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 68.90 MiB is allocated by PyTorch, and 11.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 284: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 663.62 MiB is free. Process 3432158 has 46.14 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 285: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 663.62 MiB is free. Process 3432158 has 46.14 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 286: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 663.62 MiB is free. Process 3432158 has 46.14 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 287: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 663.62 MiB is free. Process 3432158 has 46.14 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 288: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 663.62 MiB is free. Process 3432158 has 46.14 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 289: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 663.62 MiB is free. Process 3432158 has 46.14 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 290: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 663.62 MiB is free. Process 3432158 has 46.14 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 291: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 663.62 MiB is free. Process 3432158 has 46.14 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 292: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 659.62 MiB is free. Process 3432158 has 46.15 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 293: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 659.62 MiB is free. Process 3432158 has 46.15 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 34%|███▍      | 295/858 [13:34<32:58,  3.51s/it] 34%|███▍      | 296/858 [13:34<23:35,  2.52s/it] 35%|███▍      | 297/858 [13:34<17:01,  1.82s/it] 35%|███▍      | 298/858 [13:35<12:30,  1.34s/it] 35%|███▍      | 299/858 [13:35<09:22,  1.01s/it] 35%|███▍      | 300/858 [13:35<07:12,  1.29it/s] 35%|███▌      | 301/858 [13:35<05:34,  1.66it/s] 35%|███▌      | 302/858 [13:36<04:25,  2.09it/s] 35%|███▌      | 303/858 [13:36<03:35,  2.58it/s] 35%|███▌      | 304/858 [13:36<02:58,  3.10it/s] 36%|███▌      | 305/858 [13:36<02:41,  3.42it/s] 36%|███▌      | 306/858 [13:36<02:39,  3.46it/s] 36%|███▌      | 307/858 [13:50<38:25,  4.19s/it]Error on item 294: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 729.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 69.01 MiB is allocated by PyTorch, and 10.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 295: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 747.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 296: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 747.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 297: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 747.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 298: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 747.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 299: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 747.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 300: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 747.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 301: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 747.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 302: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 747.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 303: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 747.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 304: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 747.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 305: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 729.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 584.00 MiB memory in use. Of the allocated memory 60.11 MiB is allocated by PyTorch, and 13.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 306: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 453.62 MiB is free. Process 3432158 has 45.51 GiB memory in use. Including non-PyTorch memory, this process has 1.39 GiB memory in use. Of the allocated memory 369.53 MiB is allocated by PyTorch, and 546.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 36%|███▌      | 308/858 [13:56<43:37,  4.76s/it] 36%|███▌      | 309/858 [14:05<56:03,  6.13s/it] 36%|███▌      | 310/858 [14:09<49:13,  5.39s/it] 36%|███▌      | 311/858 [14:11<39:15,  4.31s/it] 36%|███▋      | 312/858 [14:11<28:03,  3.08s/it] 36%|███▋      | 313/858 [14:11<21:18,  2.35s/it] 37%|███▋      | 314/858 [14:21<40:52,  4.51s/it] 37%|███▋      | 315/858 [14:21<29:14,  3.23s/it] 37%|███▋      | 316/858 [14:21<21:00,  2.32s/it] 37%|███▋      | 317/858 [14:22<15:17,  1.70s/it] 37%|███▋      | 318/858 [14:22<11:48,  1.31s/it] 37%|███▋      | 319/858 [14:22<08:51,  1.01it/s] 37%|███▋      | 320/858 [14:22<06:39,  1.35it/s] 37%|███▋      | 321/858 [14:23<05:14,  1.71it/s] 38%|███▊      | 322/858 [14:23<04:15,  2.10it/s]Error on item 307: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 751.62 MiB is free. Process 3432158 has 46.04 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 68.87 MiB is allocated by PyTorch, and 11.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 309: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 735.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 588.00 MiB memory in use. Of the allocated memory 68.47 MiB is allocated by PyTorch, and 9.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 310: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 639.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 684.00 MiB memory in use. Of the allocated memory 160.95 MiB is allocated by PyTorch, and 13.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 311: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 751.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 312: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 701.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 614.00 MiB memory in use. Of the allocated memory 90.37 MiB is allocated by PyTorch, and 13.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 314: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 721.62 MiB is free. Process 3432158 has 46.09 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 315: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 721.62 MiB is free. Process 3432158 has 46.09 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 316: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 721.62 MiB is free. Process 3432158 has 46.09 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 317: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 695.62 MiB is free. Process 3432158 has 46.09 GiB memory in use. Including non-PyTorch memory, this process has 598.00 MiB memory in use. Of the allocated memory 76.12 MiB is allocated by PyTorch, and 11.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 318: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 721.62 MiB is free. Process 3432158 has 46.09 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 319: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 721.62 MiB is free. Process 3432158 has 46.09 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 320: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 721.62 MiB is free. Process 3432158 has 46.09 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 321: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 721.62 MiB is free. Process 3432158 has 46.09 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 38%|███▊      | 323/858 [14:23<04:21,  2.05it/s] 38%|███▊      | 324/858 [14:24<03:38,  2.45it/s] 38%|███▊      | 325/858 [14:24<03:03,  2.90it/s] 38%|███▊      | 326/858 [14:24<02:44,  3.23it/s] 38%|███▊      | 327/858 [14:24<02:34,  3.44it/s] 38%|███▊      | 328/858 [14:24<02:11,  4.02it/s] 38%|███▊      | 329/858 [14:28<12:00,  1.36s/it] 38%|███▊      | 330/858 [14:36<29:06,  3.31s/it] 39%|███▊      | 331/858 [14:42<34:46,  3.96s/it] 39%|███▊      | 332/858 [14:44<30:31,  3.48s/it] 39%|███▉      | 333/858 [14:44<21:47,  2.49s/it] 39%|███▉      | 334/858 [14:44<15:44,  1.80s/it] 39%|███▉      | 335/858 [14:55<37:19,  4.28s/it] 39%|███▉      | 336/858 [14:59<38:04,  4.38s/it] 39%|███▉      | 337/858 [15:08<50:01,  5.76s/it]Error on item 322: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 699.62 MiB is free. Process 3432158 has 46.09 GiB memory in use. Including non-PyTorch memory, this process has 594.00 MiB memory in use. Of the allocated memory 70.20 MiB is allocated by PyTorch, and 13.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 323: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 721.62 MiB is free. Process 3432158 has 46.09 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 324: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 721.62 MiB is free. Process 3432158 has 46.09 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 325: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 721.62 MiB is free. Process 3432158 has 46.09 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 326: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 715.62 MiB is free. Process 3432158 has 46.09 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 327: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 715.62 MiB is free. Process 3432158 has 46.09 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 328: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 753.62 MiB is free. Process 3432158 has 46.04 GiB memory in use. Including non-PyTorch memory, this process has 584.00 MiB memory in use. Of the allocated memory 68.35 MiB is allocated by PyTorch, and 5.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 330: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 731.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 68.94 MiB is allocated by PyTorch, and 11.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 331: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 587.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 734.00 MiB memory in use. Of the allocated memory 211.36 MiB is allocated by PyTorch, and 12.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 332: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 749.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 333: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 743.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 334: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 283.62 MiB is free. Process 3432158 has 45.87 GiB memory in use. Including non-PyTorch memory, this process has 1.21 GiB memory in use. Of the allocated memory 205.75 MiB is allocated by PyTorch, and 518.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 335: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 251.62 MiB is free. Process 3432158 has 45.91 GiB memory in use. Including non-PyTorch memory, this process has 1.19 GiB memory in use. Of the allocated memory 181.92 MiB is allocated by PyTorch, and 526.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 39%|███▉      | 338/858 [15:11<42:20,  4.89s/it] 40%|███▉      | 339/858 [15:11<30:07,  3.48s/it] 40%|███▉      | 340/858 [15:11<21:30,  2.49s/it] 40%|███▉      | 341/858 [15:12<15:34,  1.81s/it] 40%|███▉      | 342/858 [15:12<11:23,  1.32s/it] 40%|███▉      | 343/858 [15:12<08:28,  1.01it/s] 40%|████      | 344/858 [15:12<06:30,  1.32it/s] 40%|████      | 345/858 [15:13<06:06,  1.40it/s] 40%|████      | 346/858 [15:23<30:17,  3.55s/it] 40%|████      | 347/858 [15:27<32:03,  3.76s/it] 41%|████      | 348/858 [15:35<42:48,  5.04s/it] 41%|████      | 349/858 [15:43<50:36,  5.97s/it] 41%|████      | 350/858 [15:44<35:58,  4.25s/it] 41%|████      | 351/858 [15:44<25:37,  3.03s/it] 41%|████      | 352/858 [15:51<36:39,  4.35s/it] 41%|████      | 353/858 [15:51<26:07,  3.10s/it]Error on item 337: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 403.62 MiB is free. Process 3432158 has 46.38 GiB memory in use. Including non-PyTorch memory, this process has 588.00 MiB memory in use. Of the allocated memory 68.55 MiB is allocated by PyTorch, and 9.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 338: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 419.62 MiB is free. Process 3432158 has 46.38 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 339: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 419.62 MiB is free. Process 3432158 has 46.38 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 340: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 419.62 MiB is free. Process 3432158 has 46.38 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 341: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 419.62 MiB is free. Process 3432158 has 46.38 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 342: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 419.62 MiB is free. Process 3432158 has 46.38 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 343: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 419.62 MiB is free. Process 3432158 has 46.38 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 344: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 379.62 MiB is free. Process 3432158 has 46.38 GiB memory in use. Including non-PyTorch memory, this process has 608.00 MiB memory in use. Of the allocated memory 86.15 MiB is allocated by PyTorch, and 11.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 345: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 241.62 MiB is free. Process 3432158 has 45.88 GiB memory in use. Including non-PyTorch memory, this process has 1.23 GiB memory in use. Of the allocated memory 278.76 MiB is allocated by PyTorch, and 475.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 346: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 189.62 MiB is free. Process 3432158 has 46.59 GiB memory in use. Including non-PyTorch memory, this process has 588.00 MiB memory in use. Of the allocated memory 68.72 MiB is allocated by PyTorch, and 9.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 349: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 385.62 MiB is free. Process 3432158 has 46.41 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 350: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 505.62 MiB is free. Process 3432158 has 46.22 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 352: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 705.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 41%|████▏     | 354/858 [15:52<18:47,  2.24s/it] 41%|████▏     | 355/858 [15:52<13:40,  1.63s/it] 41%|████▏     | 356/858 [15:52<10:02,  1.20s/it] 42%|████▏     | 357/858 [15:52<07:32,  1.11it/s] 42%|████▏     | 358/858 [15:52<05:43,  1.45it/s] 42%|████▏     | 359/858 [15:53<04:28,  1.86it/s] 42%|████▏     | 360/858 [15:53<03:43,  2.23it/s] 42%|████▏     | 361/858 [15:53<02:59,  2.76it/s] 42%|████▏     | 362/858 [15:54<03:16,  2.52it/s] 42%|████▏     | 363/858 [15:54<02:47,  2.95it/s] 42%|████▏     | 364/858 [15:54<02:29,  3.30it/s] 43%|████▎     | 365/858 [15:54<02:15,  3.64it/s] 43%|████▎     | 366/858 [15:54<02:00,  4.10it/s]Error on item 353: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 705.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 354: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 705.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 355: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 705.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 356: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 705.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 357: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 705.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 358: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 705.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 359: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 705.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 360: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 705.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 361: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 683.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 594.00 MiB memory in use. Of the allocated memory 70.20 MiB is allocated by PyTorch, and 13.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 362: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 705.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 363: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 705.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 364: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 705.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 365: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 705.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 43%|████▎     | 367/858 [15:55<01:54,  4.29it/s] 43%|████▎     | 368/858 [15:55<01:41,  4.83it/s] 43%|████▎     | 369/858 [16:02<19:41,  2.42s/it] 43%|████▎     | 370/858 [16:05<21:28,  2.64s/it] 43%|████▎     | 371/858 [16:06<15:34,  1.92s/it] 43%|████▎     | 372/858 [16:06<11:27,  1.42s/it] 43%|████▎     | 373/858 [16:06<08:29,  1.05s/it] 44%|████▎     | 374/858 [16:06<06:25,  1.26it/s] 44%|████▎     | 375/858 [16:08<07:35,  1.06it/s] 44%|████▍     | 376/858 [16:08<05:49,  1.38it/s] 44%|████▍     | 377/858 [16:17<26:50,  3.35s/it] 44%|████▍     | 378/858 [16:20<25:51,  3.23s/it] 44%|████▍     | 379/858 [16:21<20:50,  2.61s/it] 44%|████▍     | 380/858 [16:29<31:35,  3.97s/it] 44%|████▍     | 381/858 [16:31<28:48,  3.62s/it] 45%|████▍     | 382/858 [16:32<20:35,  2.60s/it] 45%|████▍     | 383/858 [16:39<31:22,  3.96s/it]Error on item 366: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 699.62 MiB is free. Process 3432158 has 46.11 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 367: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 699.62 MiB is free. Process 3432158 has 46.11 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 369: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 603.62 MiB is free. Process 3432158 has 46.19 GiB memory in use. Including non-PyTorch memory, this process has 588.00 MiB memory in use. Of the allocated memory 68.47 MiB is allocated by PyTorch, and 9.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 370: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 619.62 MiB is free. Process 3432158 has 46.19 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 371: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 619.62 MiB is free. Process 3432158 has 46.19 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 372: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 619.62 MiB is free. Process 3432158 has 46.19 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 373: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 619.62 MiB is free. Process 3432158 has 46.19 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 374: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 527.62 MiB is free. Process 3432158 has 46.19 GiB memory in use. Including non-PyTorch memory, this process has 664.00 MiB memory in use. Of the allocated memory 140.78 MiB is allocated by PyTorch, and 13.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 375: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 613.62 MiB is free. Process 3432158 has 46.19 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 377: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 751.62 MiB is free. Process 3432158 has 46.04 GiB memory in use. Including non-PyTorch memory, this process has 584.00 MiB memory in use. Of the allocated memory 68.32 MiB is allocated by PyTorch, and 5.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 378: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 685.62 MiB is free. Process 3432158 has 46.05 GiB memory in use. Including non-PyTorch memory, this process has 644.00 MiB memory in use. Of the allocated memory 120.61 MiB is allocated by PyTorch, and 13.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 380: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 451.62 MiB is free. Process 3432158 has 46.28 GiB memory in use. Including non-PyTorch memory, this process has 646.00 MiB memory in use. Of the allocated memory 101.40 MiB is allocated by PyTorch, and 34.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 381: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 385.62 MiB is free. Process 3432158 has 46.41 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 45%|████▍     | 384/858 [16:40<25:38,  3.25s/it] 45%|████▍     | 385/858 [16:41<18:28,  2.34s/it] 45%|████▍     | 386/858 [16:41<13:24,  1.70s/it] 45%|████▌     | 387/858 [16:41<09:47,  1.25s/it] 45%|████▌     | 388/858 [16:54<38:05,  4.86s/it] 45%|████▌     | 389/858 [16:57<33:37,  4.30s/it] 45%|████▌     | 390/858 [17:06<43:53,  5.63s/it] 46%|████▌     | 391/858 [17:13<47:51,  6.15s/it] 46%|████▌     | 392/858 [17:21<50:33,  6.51s/it] 46%|████▌     | 393/858 [17:30<56:12,  7.25s/it] 46%|████▌     | 394/858 [17:30<41:06,  5.31s/it] 46%|████▌     | 395/858 [17:38<46:55,  6.08s/it] 46%|████▌     | 396/858 [17:46<50:11,  6.52s/it] 46%|████▋     | 397/858 [17:50<45:20,  5.90s/it] 46%|████▋     | 398/858 [17:50<32:05,  4.19s/it] 47%|████▋     | 399/858 [17:51<22:56,  3.00s/it] 47%|████▋     | 400/858 [17:51<16:30,  2.16s/it] 47%|████▋     | 401/858 [17:51<12:00,  1.58s/it]Error on item 383: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 467.62 MiB is free. Process 3432158 has 46.22 GiB memory in use. Including non-PyTorch memory, this process has 688.00 MiB memory in use. Of the allocated memory 166.43 MiB is allocated by PyTorch, and 11.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 384: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 583.62 MiB is free. Process 3432158 has 46.22 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 385: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 583.62 MiB is free. Process 3432158 has 46.22 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 386: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 583.62 MiB is free. Process 3432158 has 46.22 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 387: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 297.62 MiB is free. Process 3432158 has 46.04 GiB memory in use. Including non-PyTorch memory, this process has 1.02 GiB memory in use. Of the allocated memory 414.37 MiB is allocated by PyTorch, and 121.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 388: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 753.62 MiB is free. Process 3432158 has 46.04 GiB memory in use. Including non-PyTorch memory, this process has 584.00 MiB memory in use. Of the allocated memory 68.35 MiB is allocated by PyTorch, and 5.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 392: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 745.62 MiB is free. Process 3432158 has 46.04 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 69.25 MiB is allocated by PyTorch, and 10.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 393: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 717.62 MiB is free. Process 3432158 has 46.04 GiB memory in use. Including non-PyTorch memory, this process has 618.00 MiB memory in use. Of the allocated memory 96.19 MiB is allocated by PyTorch, and 11.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 396: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 579.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 68.87 MiB is allocated by PyTorch, and 11.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 397: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 597.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 398: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 597.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 399: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 597.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 400: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 597.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 47%|████▋     | 402/858 [17:51<08:48,  1.16s/it] 47%|████▋     | 403/858 [17:52<06:38,  1.14it/s] 47%|████▋     | 404/858 [17:52<05:05,  1.49it/s] 47%|████▋     | 405/858 [17:52<04:00,  1.88it/s] 47%|████▋     | 406/858 [17:52<03:12,  2.35it/s] 47%|████▋     | 407/858 [17:52<02:39,  2.82it/s] 48%|████▊     | 408/858 [17:52<02:18,  3.25it/s] 48%|████▊     | 409/858 [17:53<02:01,  3.69it/s] 48%|████▊     | 410/858 [17:53<01:52,  3.97it/s] 48%|████▊     | 411/858 [17:53<01:45,  4.24it/s] 48%|████▊     | 412/858 [17:53<01:44,  4.28it/s] 48%|████▊     | 413/858 [17:54<01:43,  4.31it/s] 48%|████▊     | 414/858 [17:54<01:30,  4.89it/s] 48%|████▊     | 415/858 [18:03<21:25,  2.90s/it]Error on item 401: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 597.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 402: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 597.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 403: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 597.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 404: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 597.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 405: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 597.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 406: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 597.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 407: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 597.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 408: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 597.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 409: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 597.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 410: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 597.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 411: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 597.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 412: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 591.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 413: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 591.62 MiB is free. Process 3432158 has 46.47 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 48%|████▊     | 416/858 [18:11<33:50,  4.59s/it] 49%|████▊     | 417/858 [18:12<24:17,  3.30s/it] 49%|████▊     | 418/858 [18:12<17:22,  2.37s/it] 49%|████▉     | 419/858 [18:12<12:33,  1.72s/it] 49%|████▉     | 420/858 [18:12<09:12,  1.26s/it] 49%|████▉     | 421/858 [18:13<06:57,  1.05it/s] 49%|████▉     | 422/858 [18:13<05:21,  1.36it/s] 49%|████▉     | 423/858 [18:13<04:10,  1.74it/s] 49%|████▉     | 424/858 [18:13<03:24,  2.12it/s] 50%|████▉     | 425/858 [18:13<02:45,  2.62it/s] 50%|████▉     | 426/858 [18:14<02:19,  3.10it/s] 50%|████▉     | 427/858 [18:14<02:01,  3.55it/s] 50%|████▉     | 428/858 [18:29<33:24,  4.66s/it] 50%|█████     | 429/858 [18:37<41:06,  5.75s/it]Error on item 415: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 635.62 MiB is free. Process 3432158 has 46.15 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 68.90 MiB is allocated by PyTorch, and 11.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 416: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 641.62 MiB is free. Process 3432158 has 46.15 GiB memory in use. Including non-PyTorch memory, this process has 584.00 MiB memory in use. Of the allocated memory 60.11 MiB is allocated by PyTorch, and 13.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 417: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 653.62 MiB is free. Process 3432158 has 46.15 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 418: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 653.62 MiB is free. Process 3432158 has 46.15 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 419: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 653.62 MiB is free. Process 3432158 has 46.15 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 420: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 653.62 MiB is free. Process 3432158 has 46.15 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 421: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 653.62 MiB is free. Process 3432158 has 46.15 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 422: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 653.62 MiB is free. Process 3432158 has 46.15 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 423: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 653.62 MiB is free. Process 3432158 has 46.15 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 424: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 653.62 MiB is free. Process 3432158 has 46.15 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 425: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 649.62 MiB is free. Process 3432158 has 46.16 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 426: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 649.62 MiB is free. Process 3432158 has 46.16 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 428: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 471.62 MiB is free. Process 3432158 has 46.27 GiB memory in use. Including non-PyTorch memory, this process has 634.00 MiB memory in use. Of the allocated memory 83.81 MiB is allocated by PyTorch, and 40.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 50%|█████     | 430/858 [18:37<29:11,  4.09s/it] 50%|█████     | 431/858 [18:37<20:51,  2.93s/it] 50%|█████     | 432/858 [18:38<15:04,  2.12s/it] 50%|█████     | 433/858 [18:38<10:57,  1.55s/it] 51%|█████     | 434/858 [18:38<08:16,  1.17s/it] 51%|█████     | 435/858 [18:38<06:11,  1.14it/s] 51%|█████     | 436/858 [18:39<04:48,  1.46it/s] 51%|█████     | 437/858 [18:39<03:47,  1.85it/s] 51%|█████     | 438/858 [18:39<03:04,  2.28it/s] 51%|█████     | 439/858 [18:39<02:38,  2.65it/s] 51%|█████▏    | 440/858 [18:39<02:20,  2.98it/s] 51%|█████▏    | 441/858 [18:40<02:00,  3.47it/s] 52%|█████▏    | 442/858 [18:50<23:57,  3.45s/it]Error on item 429: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 533.62 MiB is free. Process 3432158 has 46.27 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 430: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 533.62 MiB is free. Process 3432158 has 46.27 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 431: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 533.62 MiB is free. Process 3432158 has 46.27 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 432: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 533.62 MiB is free. Process 3432158 has 46.27 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 433: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 533.62 MiB is free. Process 3432158 has 46.27 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 434: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 533.62 MiB is free. Process 3432158 has 46.27 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 435: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 533.62 MiB is free. Process 3432158 has 46.27 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 436: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 533.62 MiB is free. Process 3432158 has 46.27 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 437: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 533.62 MiB is free. Process 3432158 has 46.27 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 438: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 533.62 MiB is free. Process 3432158 has 46.27 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 439: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 527.62 MiB is free. Process 3432158 has 46.28 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 440: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 527.62 MiB is free. Process 3432158 has 46.28 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 441: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 719.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 68.80 MiB is allocated by PyTorch, and 11.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 52%|█████▏    | 443/858 [18:51<17:12,  2.49s/it] 52%|█████▏    | 444/858 [18:51<13:16,  1.92s/it] 52%|█████▏    | 445/858 [18:51<09:42,  1.41s/it] 52%|█████▏    | 446/858 [18:52<07:15,  1.06s/it] 52%|█████▏    | 447/858 [18:52<05:32,  1.23it/s] 52%|█████▏    | 448/858 [18:52<04:16,  1.60it/s] 52%|█████▏    | 449/858 [18:52<03:21,  2.03it/s] 52%|█████▏    | 450/858 [19:08<34:44,  5.11s/it] 53%|█████▎    | 451/858 [19:18<45:01,  6.64s/it] 53%|█████▎    | 452/858 [19:28<50:08,  7.41s/it] 53%|█████▎    | 453/858 [19:31<41:51,  6.20s/it] 53%|█████▎    | 454/858 [19:31<29:43,  4.42s/it] 53%|█████▎    | 455/858 [19:31<21:08,  3.15s/it] 53%|█████▎    | 456/858 [19:33<17:31,  2.62s/it] 53%|█████▎    | 457/858 [19:42<30:10,  4.52s/it] 53%|█████▎    | 458/858 [19:43<23:35,  3.54s/it] 53%|█████▎    | 459/858 [19:51<33:17,  5.01s/it] 54%|█████▎    | 460/858 [19:57<33:30,  5.05s/it]Error on item 442: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 737.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 443: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 705.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 604.00 MiB memory in use. Of the allocated memory 80.28 MiB is allocated by PyTorch, and 13.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 444: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 737.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 445: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 737.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 446: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 737.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 447: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 731.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 448: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 731.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 452: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 613.62 MiB is free. Process 3432158 has 46.18 GiB memory in use. Including non-PyTorch memory, this process has 588.00 MiB memory in use. Of the allocated memory 68.43 MiB is allocated by PyTorch, and 9.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 453: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 629.62 MiB is free. Process 3432158 has 46.18 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 454: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 629.62 MiB is free. Process 3432158 has 46.18 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 455: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 523.62 MiB is free. Process 3432158 has 46.18 GiB memory in use. Including non-PyTorch memory, this process has 674.00 MiB memory in use. Of the allocated memory 150.87 MiB is allocated by PyTorch, and 13.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 457: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 707.62 MiB is free. Process 3432158 has 46.02 GiB memory in use. Including non-PyTorch memory, this process has 658.00 MiB memory in use. Of the allocated memory 136.32 MiB is allocated by PyTorch, and 11.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 459: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 649.62 MiB is free. Process 3432158 has 46.14 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 69.04 MiB is allocated by PyTorch, and 10.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 54%|█████▎    | 461/858 [19:57<23:56,  3.62s/it] 54%|█████▍    | 462/858 [19:57<17:12,  2.61s/it] 54%|█████▍    | 463/858 [19:57<12:22,  1.88s/it] 54%|█████▍    | 464/858 [19:59<12:51,  1.96s/it] 54%|█████▍    | 465/858 [20:14<38:33,  5.89s/it] 54%|█████▍    | 466/858 [20:23<44:15,  6.77s/it] 54%|█████▍    | 467/858 [20:33<48:51,  7.50s/it] 55%|█████▍    | 468/858 [20:33<34:34,  5.32s/it] 55%|█████▍    | 469/858 [20:34<25:53,  3.99s/it] 55%|█████▍    | 470/858 [20:34<18:27,  2.85s/it] 55%|█████▍    | 471/858 [20:34<13:14,  2.05s/it] 55%|█████▌    | 472/858 [20:51<41:44,  6.49s/it] 55%|█████▌    | 473/858 [20:55<37:34,  5.86s/it] 55%|█████▌    | 474/858 [20:55<26:40,  4.17s/it] 55%|█████▌    | 475/858 [20:56<19:03,  2.99s/it] 55%|█████▌    | 476/858 [20:56<14:24,  2.26s/it]Error on item 460: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 667.62 MiB is free. Process 3432158 has 46.14 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 461: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 667.62 MiB is free. Process 3432158 has 46.14 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 462: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 667.62 MiB is free. Process 3432158 has 46.14 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 463: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 519.62 MiB is free. Process 3432158 has 46.14 GiB memory in use. Including non-PyTorch memory, this process has 714.00 MiB memory in use. Of the allocated memory 191.20 MiB is allocated by PyTorch, and 12.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 466: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 625.62 MiB is free. Process 3432158 has 46.16 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 68.97 MiB is allocated by PyTorch, and 11.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 467: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 643.62 MiB is free. Process 3432158 has 46.16 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 468: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 577.62 MiB is free. Process 3432158 has 46.16 GiB memory in use. Including non-PyTorch memory, this process has 638.00 MiB memory in use. Of the allocated memory 116.26 MiB is allocated by PyTorch, and 11.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 469: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 643.62 MiB is free. Process 3432158 has 46.16 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 470: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 643.62 MiB is free. Process 3432158 has 46.16 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 472: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 711.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 68.97 MiB is allocated by PyTorch, and 11.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 473: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 729.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 474: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 729.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 475: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 697.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 604.00 MiB memory in use. Of the allocated memory 80.28 MiB is allocated by PyTorch, and 13.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 56%|█████▌    | 477/858 [20:57<10:28,  1.65s/it] 56%|█████▌    | 478/858 [20:57<07:39,  1.21s/it] 56%|█████▌    | 479/858 [20:57<06:41,  1.06s/it] 56%|█████▌    | 480/858 [20:58<05:11,  1.21it/s] 56%|█████▌    | 481/858 [20:58<03:59,  1.58it/s] 56%|█████▌    | 482/858 [21:09<24:06,  3.85s/it] 56%|█████▋    | 483/858 [21:10<17:51,  2.86s/it] 56%|█████▋    | 484/858 [21:10<12:54,  2.07s/it] 57%|█████▋    | 485/858 [21:10<09:24,  1.51s/it] 57%|█████▋    | 486/858 [21:10<06:57,  1.12s/it] 57%|█████▋    | 487/858 [21:11<05:15,  1.17it/s] 57%|█████▋    | 488/858 [21:11<04:00,  1.54it/s] 57%|█████▋    | 489/858 [21:11<03:10,  1.94it/s] 57%|█████▋    | 490/858 [21:21<21:12,  3.46s/it]Error on item 476: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 729.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 477: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 729.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 478: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 687.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 614.00 MiB memory in use. Of the allocated memory 90.37 MiB is allocated by PyTorch, and 13.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 479: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 681.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 614.00 MiB memory in use. Of the allocated memory 60.11 MiB is allocated by PyTorch, and 43.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 480: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 723.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 481: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 539.62 MiB is free. Process 3432158 has 46.25 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 69.08 MiB is allocated by PyTorch, and 10.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 482: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 525.62 MiB is free. Process 3432158 has 46.25 GiB memory in use. Including non-PyTorch memory, this process has 604.00 MiB memory in use. Of the allocated memory 80.28 MiB is allocated by PyTorch, and 13.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 483: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 557.62 MiB is free. Process 3432158 has 46.25 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 484: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 557.62 MiB is free. Process 3432158 has 46.25 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 485: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 557.62 MiB is free. Process 3432158 has 46.25 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 486: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 557.62 MiB is free. Process 3432158 has 46.25 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 487: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 557.62 MiB is free. Process 3432158 has 46.25 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 488: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 557.62 MiB is free. Process 3432158 has 46.25 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 57%|█████▋    | 491/858 [21:31<32:05,  5.25s/it] 57%|█████▋    | 492/858 [21:31<22:53,  3.75s/it] 57%|█████▋    | 493/858 [21:31<16:22,  2.69s/it] 58%|█████▊    | 494/858 [21:31<11:48,  1.95s/it] 58%|█████▊    | 495/858 [21:32<08:38,  1.43s/it] 58%|█████▊    | 496/858 [21:32<06:24,  1.06s/it] 58%|█████▊    | 497/858 [21:32<04:48,  1.25it/s] 58%|█████▊    | 498/858 [21:32<03:45,  1.60it/s] 58%|█████▊    | 499/858 [21:32<02:55,  2.05it/s] 58%|█████▊    | 500/858 [21:43<21:20,  3.58s/it] 58%|█████▊    | 501/858 [21:45<17:36,  2.96s/it] 59%|█████▊    | 502/858 [21:45<12:38,  2.13s/it] 59%|█████▊    | 503/858 [21:45<09:13,  1.56s/it]Error on item 490: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 727.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 69.15 MiB is allocated by PyTorch, and 10.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 491: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 745.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 492: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 745.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 493: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 745.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 494: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 745.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 495: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 745.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 496: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 745.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 497: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 737.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 498: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 737.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 499: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 711.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 68.87 MiB is allocated by PyTorch, and 11.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 500: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 633.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 668.00 MiB memory in use. Of the allocated memory 146.36 MiB is allocated by PyTorch, and 11.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 501: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 729.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 502: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 729.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 59%|█████▊    | 504/858 [21:45<06:50,  1.16s/it] 59%|█████▉    | 505/858 [21:46<05:10,  1.14it/s] 59%|█████▉    | 506/858 [21:55<20:18,  3.46s/it] 59%|█████▉    | 507/858 [22:05<31:25,  5.37s/it] 59%|█████▉    | 508/858 [22:06<23:34,  4.04s/it] 59%|█████▉    | 509/858 [22:14<31:05,  5.35s/it] 59%|█████▉    | 510/858 [22:19<29:39,  5.11s/it] 60%|█████▉    | 511/858 [22:19<21:05,  3.65s/it] 60%|█████▉    | 512/858 [22:19<15:05,  2.62s/it] 60%|█████▉    | 513/858 [22:20<10:55,  1.90s/it] 60%|█████▉    | 514/858 [22:20<07:57,  1.39s/it] 60%|██████    | 515/858 [22:24<12:24,  2.17s/it] 60%|██████    | 516/858 [22:32<23:18,  4.09s/it] 60%|██████    | 517/858 [22:32<16:35,  2.92s/it] 60%|██████    | 518/858 [22:33<11:53,  2.10s/it]Error on item 503: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 729.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 504: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 723.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 506: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 173.62 MiB is free. Process 3432158 has 45.98 GiB memory in use. Including non-PyTorch memory, this process has 1.20 GiB memory in use. Of the allocated memory 190.91 MiB is allocated by PyTorch, and 527.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 507: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 235.62 MiB is free. Process 3432158 has 45.98 GiB memory in use. Including non-PyTorch memory, this process has 1.14 GiB memory in use. Of the allocated memory 115.57 MiB is allocated by PyTorch, and 540.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 509: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 457.62 MiB is free. Process 3432158 has 46.33 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 68.90 MiB is allocated by PyTorch, and 11.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 510: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 475.62 MiB is free. Process 3432158 has 46.33 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 511: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 475.62 MiB is free. Process 3432158 has 46.33 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 512: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 475.62 MiB is free. Process 3432158 has 46.33 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 513: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 475.62 MiB is free. Process 3432158 has 46.33 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 514: CUDA out of memory. Tried to allocate 116.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 197.62 MiB is free. Process 3432158 has 45.43 GiB memory in use. Including non-PyTorch memory, this process has 1.49 GiB memory in use. Of the allocated memory 947.66 MiB is allocated by PyTorch, and 70.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 515: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 517.62 MiB is free. Process 3432158 has 46.27 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 69.01 MiB is allocated by PyTorch, and 10.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 516: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 535.62 MiB is free. Process 3432158 has 46.27 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 517: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 535.62 MiB is free. Process 3432158 has 46.27 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 60%|██████    | 519/858 [22:33<08:36,  1.52s/it] 61%|██████    | 520/858 [22:33<06:21,  1.13s/it] 61%|██████    | 521/858 [22:33<04:50,  1.16it/s] 61%|██████    | 522/858 [22:33<03:41,  1.52it/s] 61%|██████    | 523/858 [22:34<02:52,  1.94it/s] 61%|██████    | 524/858 [22:34<02:20,  2.38it/s] 61%|██████    | 525/858 [22:34<02:30,  2.22it/s] 61%|██████▏   | 526/858 [22:45<18:40,  3.38s/it] 61%|██████▏   | 527/858 [22:45<13:24,  2.43s/it] 62%|██████▏   | 528/858 [22:45<09:44,  1.77s/it] 62%|██████▏   | 529/858 [22:46<08:21,  1.52s/it] 62%|██████▏   | 530/858 [22:46<06:14,  1.14s/it] 62%|██████▏   | 531/858 [22:47<05:01,  1.08it/s] 62%|██████▏   | 532/858 [22:47<04:08,  1.31it/s]Error on item 518: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 535.62 MiB is free. Process 3432158 has 46.27 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 519: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 535.62 MiB is free. Process 3432158 has 46.27 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 520: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 535.62 MiB is free. Process 3432158 has 46.27 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 521: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 535.62 MiB is free. Process 3432158 has 46.27 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 522: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 535.62 MiB is free. Process 3432158 has 46.27 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 523: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 535.62 MiB is free. Process 3432158 has 46.27 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 524: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 503.62 MiB is free. Process 3432158 has 46.27 GiB memory in use. Including non-PyTorch memory, this process has 604.00 MiB memory in use. Of the allocated memory 80.28 MiB is allocated by PyTorch, and 13.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 526: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 377.62 MiB is free. Process 3432158 has 46.42 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 527: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 377.62 MiB is free. Process 3432158 has 46.42 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 528: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 321.62 MiB is free. Process 3432158 has 46.42 GiB memory in use. Including non-PyTorch memory, this process has 628.00 MiB memory in use. Of the allocated memory 106.22 MiB is allocated by PyTorch, and 11.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 529: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 377.62 MiB is free. Process 3432158 has 46.42 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 530: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 361.62 MiB is free. Process 3432158 has 46.42 GiB memory in use. Including non-PyTorch memory, this process has 588.00 MiB memory in use. Of the allocated memory 66.08 MiB is allocated by PyTorch, and 11.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 531: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 361.62 MiB is free. Process 3432158 has 46.42 GiB memory in use. Including non-PyTorch memory, this process has 588.00 MiB memory in use. Of the allocated memory 66.08 MiB is allocated by PyTorch, and 11.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 62%|██████▏   | 533/858 [22:47<03:15,  1.66it/s] 62%|██████▏   | 534/858 [22:48<03:14,  1.67it/s] 62%|██████▏   | 535/858 [22:48<02:35,  2.07it/s] 62%|██████▏   | 536/858 [22:57<15:31,  2.89s/it] 63%|██████▎   | 537/858 [22:59<15:22,  2.87s/it] 63%|██████▎   | 538/858 [23:00<11:06,  2.08s/it] 63%|██████▎   | 539/858 [23:01<09:09,  1.72s/it] 63%|██████▎   | 540/858 [23:01<06:45,  1.28s/it] 63%|██████▎   | 541/858 [23:01<05:06,  1.04it/s] 63%|██████▎   | 542/858 [23:01<03:56,  1.34it/s] 63%|██████▎   | 543/858 [23:01<03:00,  1.75it/s] 63%|██████▎   | 544/858 [23:02<02:22,  2.20it/s] 64%|██████▎   | 545/858 [23:09<13:54,  2.67s/it] 64%|██████▎   | 546/858 [23:12<14:27,  2.78s/it] 64%|██████▍   | 547/858 [23:13<10:24,  2.01s/it]Error on item 532: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 377.62 MiB is free. Process 3432158 has 46.42 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 533: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 341.62 MiB is free. Process 3432158 has 46.42 GiB memory in use. Including non-PyTorch memory, this process has 608.00 MiB memory in use. Of the allocated memory 86.15 MiB is allocated by PyTorch, and 11.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 534: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 375.62 MiB is free. Process 3432158 has 46.42 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 536: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 643.62 MiB is free. Process 3432158 has 46.15 GiB memory in use. Including non-PyTorch memory, this process has 588.00 MiB memory in use. Of the allocated memory 68.67 MiB is allocated by PyTorch, and 9.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 537: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 659.62 MiB is free. Process 3432158 has 46.15 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 538: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 607.62 MiB is free. Process 3432158 has 46.15 GiB memory in use. Including non-PyTorch memory, this process has 624.00 MiB memory in use. Of the allocated memory 100.45 MiB is allocated by PyTorch, and 13.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 539: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 659.62 MiB is free. Process 3432158 has 46.15 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 540: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 659.62 MiB is free. Process 3432158 has 46.15 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 541: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 659.62 MiB is free. Process 3432158 has 46.15 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 542: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 655.62 MiB is free. Process 3432158 has 46.15 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 543: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 655.62 MiB is free. Process 3432158 has 46.15 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 545: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 709.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 588.00 MiB memory in use. Of the allocated memory 68.59 MiB is allocated by PyTorch, and 9.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 546: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 725.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 64%|██████▍   | 548/858 [23:13<07:36,  1.47s/it] 64%|██████▍   | 549/858 [23:14<06:48,  1.32s/it] 64%|██████▍   | 550/858 [23:14<05:06,  1.01it/s] 64%|██████▍   | 551/858 [23:14<03:52,  1.32it/s] 64%|██████▍   | 552/858 [23:14<02:57,  1.73it/s] 64%|██████▍   | 553/858 [23:24<16:40,  3.28s/it] 65%|██████▍   | 554/858 [23:33<24:41,  4.87s/it] 65%|██████▍   | 555/858 [23:37<24:34,  4.87s/it] 65%|██████▍   | 556/858 [23:48<32:46,  6.51s/it] 65%|██████▍   | 557/858 [23:52<29:45,  5.93s/it] 65%|██████▌   | 558/858 [23:53<21:06,  4.22s/it] 65%|██████▌   | 559/858 [23:53<15:04,  3.02s/it] 65%|██████▌   | 560/858 [23:53<10:49,  2.18s/it] 65%|██████▌   | 561/858 [23:53<07:51,  1.59s/it] 66%|██████▌   | 562/858 [23:53<05:47,  1.17s/it] 66%|██████▌   | 563/858 [23:54<04:18,  1.14it/s]Error on item 547: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 725.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 548: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 663.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 634.00 MiB memory in use. Of the allocated memory 110.53 MiB is allocated by PyTorch, and 13.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 549: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 725.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 550: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 719.62 MiB is free. Process 3432158 has 46.09 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 551: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 719.62 MiB is free. Process 3432158 has 46.09 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 554: CUDA out of memory. Tried to allocate 212.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 277.62 MiB is free. Process 3432158 has 45.37 GiB memory in use. Including non-PyTorch memory, this process has 1.73 GiB memory in use. Of the allocated memory 998.03 MiB is allocated by PyTorch, and 261.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 556: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 461.62 MiB is free. Process 3432158 has 46.32 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 69.15 MiB is allocated by PyTorch, and 10.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 557: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 239.62 MiB is free. Process 3432158 has 46.56 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 558: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 239.62 MiB is free. Process 3432158 has 46.56 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 559: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 239.62 MiB is free. Process 3432158 has 46.56 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 560: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 239.62 MiB is free. Process 3432158 has 46.56 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 561: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 239.62 MiB is free. Process 3432158 has 46.56 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 562: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 239.62 MiB is free. Process 3432158 has 46.56 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 66%|██████▌   | 564/858 [23:54<03:19,  1.48it/s] 66%|██████▌   | 565/858 [23:54<02:35,  1.88it/s] 66%|██████▌   | 566/858 [23:54<02:04,  2.34it/s] 66%|██████▌   | 567/858 [23:54<01:43,  2.82it/s] 66%|██████▌   | 568/858 [23:55<01:27,  3.31it/s] 66%|██████▋   | 569/858 [23:55<01:16,  3.76it/s] 66%|██████▋   | 570/858 [23:55<01:09,  4.12it/s] 67%|██████▋   | 571/858 [23:55<01:04,  4.44it/s] 67%|██████▋   | 572/858 [23:55<01:03,  4.53it/s] 67%|██████▋   | 573/858 [23:56<01:01,  4.62it/s] 67%|██████▋   | 574/858 [23:56<00:55,  5.08it/s] 67%|██████▋   | 575/858 [23:59<04:51,  1.03s/it] 67%|██████▋   | 576/858 [23:59<03:41,  1.28it/s]Error on item 563: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 239.62 MiB is free. Process 3432158 has 46.56 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 564: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 239.62 MiB is free. Process 3432158 has 46.56 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 565: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 239.62 MiB is free. Process 3432158 has 46.56 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 566: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 239.62 MiB is free. Process 3432158 has 46.56 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 567: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 239.62 MiB is free. Process 3432158 has 46.56 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 568: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 239.62 MiB is free. Process 3432158 has 46.56 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 569: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 239.62 MiB is free. Process 3432158 has 46.56 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 570: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 239.62 MiB is free. Process 3432158 has 46.56 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 571: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 239.62 MiB is free. Process 3432158 has 46.56 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 572: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 233.62 MiB is free. Process 3432158 has 46.56 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 573: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 233.62 MiB is free. Process 3432158 has 46.56 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 574: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 279.62 MiB is free. Process 3432158 has 46.50 GiB memory in use. Including non-PyTorch memory, this process has 588.00 MiB memory in use. Of the allocated memory 68.59 MiB is allocated by PyTorch, and 9.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 575: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 295.62 MiB is free. Process 3432158 has 46.50 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 67%|██████▋   | 577/858 [23:59<02:54,  1.61it/s] 67%|██████▋   | 578/858 [23:59<02:18,  2.02it/s] 67%|██████▋   | 579/858 [24:00<01:57,  2.38it/s] 68%|██████▊   | 580/858 [24:00<01:38,  2.84it/s] 68%|██████▊   | 581/858 [24:00<01:23,  3.30it/s] 68%|██████▊   | 582/858 [24:01<02:22,  1.93it/s] 68%|██████▊   | 583/858 [24:01<01:59,  2.30it/s] 68%|██████▊   | 584/858 [24:01<01:42,  2.68it/s] 68%|██████▊   | 585/858 [24:02<01:28,  3.08it/s] 68%|██████▊   | 586/858 [24:02<01:19,  3.43it/s] 68%|██████▊   | 587/858 [24:02<01:11,  3.81it/s] 69%|██████▊   | 588/858 [24:09<10:15,  2.28s/it] 69%|██████▊   | 589/858 [24:12<11:13,  2.50s/it] 69%|██████▉   | 590/858 [24:13<09:03,  2.03s/it]Error on item 576: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 295.62 MiB is free. Process 3432158 has 46.50 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 577: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 295.62 MiB is free. Process 3432158 has 46.50 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 578: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 295.62 MiB is free. Process 3432158 has 46.50 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 579: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 295.62 MiB is free. Process 3432158 has 46.50 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 580: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 295.62 MiB is free. Process 3432158 has 46.50 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 581: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 239.62 MiB is free. Process 3432158 has 46.50 GiB memory in use. Including non-PyTorch memory, this process has 628.00 MiB memory in use. Of the allocated memory 106.22 MiB is allocated by PyTorch, and 11.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 582: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 295.62 MiB is free. Process 3432158 has 46.50 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 583: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 295.62 MiB is free. Process 3432158 has 46.50 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 584: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 295.62 MiB is free. Process 3432158 has 46.50 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 585: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 295.62 MiB is free. Process 3432158 has 46.50 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 586: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 769.62 MiB is free. Process 3432158 has 45.98 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 588: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 675.62 MiB is free. Process 3432158 has 46.12 GiB memory in use. Including non-PyTorch memory, this process has 588.00 MiB memory in use. Of the allocated memory 68.63 MiB is allocated by PyTorch, and 9.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 589: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 639.62 MiB is free. Process 3432158 has 46.12 GiB memory in use. Including non-PyTorch memory, this process has 624.00 MiB memory in use. Of the allocated memory 100.45 MiB is allocated by PyTorch, and 13.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 69%|██████▉   | 591/858 [24:13<06:39,  1.50s/it] 69%|██████▉   | 592/858 [24:14<05:03,  1.14s/it] 69%|██████▉   | 593/858 [24:14<03:49,  1.16it/s] 69%|██████▉   | 594/858 [24:14<02:54,  1.51it/s] 69%|██████▉   | 595/858 [24:14<02:18,  1.90it/s] 69%|██████▉   | 596/858 [24:14<01:53,  2.31it/s] 70%|██████▉   | 597/858 [24:15<01:36,  2.70it/s] 70%|██████▉   | 598/858 [24:15<01:24,  3.09it/s] 70%|██████▉   | 599/858 [24:15<01:13,  3.53it/s] 70%|██████▉   | 600/858 [24:15<01:05,  3.94it/s] 70%|███████   | 601/858 [24:17<03:34,  1.20it/s] 70%|███████   | 602/858 [24:26<13:09,  3.08s/it] 70%|███████   | 603/858 [24:26<09:26,  2.22s/it]Error on item 590: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 691.62 MiB is free. Process 3432158 has 46.12 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 591: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 679.62 MiB is free. Process 3432158 has 46.12 GiB memory in use. Including non-PyTorch memory, this process has 584.00 MiB memory in use. Of the allocated memory 60.11 MiB is allocated by PyTorch, and 13.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 592: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 691.62 MiB is free. Process 3432158 has 46.12 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 593: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 691.62 MiB is free. Process 3432158 has 46.12 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 594: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 691.62 MiB is free. Process 3432158 has 46.12 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 595: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 691.62 MiB is free. Process 3432158 has 46.12 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 596: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 691.62 MiB is free. Process 3432158 has 46.12 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 597: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 691.62 MiB is free. Process 3432158 has 46.12 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 598: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 685.62 MiB is free. Process 3432158 has 46.12 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 599: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 623.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 600: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 183.62 MiB is free. Process 3432158 has 46.29 GiB memory in use. Including non-PyTorch memory, this process has 640.00 MiB memory in use. Of the allocated memory 73.47 MiB is allocated by PyTorch, and 56.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 601: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 729.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 69.04 MiB is allocated by PyTorch, and 10.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 602: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 747.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 70%|███████   | 604/858 [24:27<07:53,  1.87s/it] 71%|███████   | 605/858 [24:28<07:10,  1.70s/it] 71%|███████   | 606/858 [24:29<05:13,  1.24s/it] 71%|███████   | 607/858 [24:36<13:17,  3.18s/it] 71%|███████   | 608/858 [24:44<19:05,  4.58s/it] 71%|███████   | 609/858 [24:52<23:21,  5.63s/it] 71%|███████   | 610/858 [25:00<25:58,  6.28s/it] 71%|███████   | 611/858 [25:07<27:20,  6.64s/it] 71%|███████▏  | 612/858 [25:08<19:51,  4.84s/it] 71%|███████▏  | 613/858 [25:08<14:06,  3.46s/it] 72%|███████▏  | 614/858 [25:09<10:07,  2.49s/it] 72%|███████▏  | 615/858 [25:09<07:18,  1.81s/it] 72%|███████▏  | 616/858 [25:09<05:22,  1.33s/it] 72%|███████▏  | 617/858 [25:09<03:59,  1.01it/s] 72%|███████▏  | 618/858 [25:09<03:00,  1.33it/s] 72%|███████▏  | 619/858 [25:10<02:20,  1.70it/s] 72%|███████▏  | 620/858 [25:20<14:01,  3.53s/it]Error on item 603: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 691.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 628.00 MiB memory in use. Of the allocated memory 106.22 MiB is allocated by PyTorch, and 11.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 604: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 645.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 668.00 MiB memory in use. Of the allocated memory 146.36 MiB is allocated by PyTorch, and 11.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 605: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 299.62 MiB is free. Process 3432158 has 46.01 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 610: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 695.62 MiB is free. Process 3432158 has 46.09 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 68.94 MiB is allocated by PyTorch, and 11.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 611: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 677.62 MiB is free. Process 3432158 has 46.09 GiB memory in use. Including non-PyTorch memory, this process has 608.00 MiB memory in use. Of the allocated memory 86.15 MiB is allocated by PyTorch, and 11.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 612: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 713.62 MiB is free. Process 3432158 has 46.09 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 613: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 713.62 MiB is free. Process 3432158 has 46.09 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 614: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 713.62 MiB is free. Process 3432158 has 46.09 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 615: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 713.62 MiB is free. Process 3432158 has 46.09 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 616: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 713.62 MiB is free. Process 3432158 has 46.09 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 617: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 713.62 MiB is free. Process 3432158 has 46.09 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 618: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 713.62 MiB is free. Process 3432158 has 46.09 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 619: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 181.62 MiB is free. Process 3432158 has 45.94 GiB memory in use. Including non-PyTorch memory, this process has 1.21 GiB memory in use. Of the allocated memory 221.24 MiB is allocated by PyTorch, and 508.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 72%|███████▏  | 621/858 [25:32<24:20,  6.16s/it] 72%|███████▏  | 622/858 [25:41<27:51,  7.08s/it] 73%|███████▎  | 623/858 [25:42<20:22,  5.20s/it] 73%|███████▎  | 624/858 [25:43<14:28,  3.71s/it] 73%|███████▎  | 625/858 [25:43<10:21,  2.67s/it] 73%|███████▎  | 626/858 [25:43<07:27,  1.93s/it] 73%|███████▎  | 627/858 [25:43<05:25,  1.41s/it] 73%|███████▎  | 628/858 [25:43<03:58,  1.04s/it] 73%|███████▎  | 629/858 [25:44<03:03,  1.25it/s] 73%|███████▎  | 630/858 [25:44<02:23,  1.59it/s] 74%|███████▎  | 631/858 [25:44<01:52,  2.02it/s] 74%|███████▎  | 632/858 [25:44<01:34,  2.39it/s] 74%|███████▍  | 633/858 [25:44<01:19,  2.84it/s] 74%|███████▍  | 634/858 [25:45<01:09,  3.24it/s] 74%|███████▍  | 635/858 [25:59<17:15,  4.64s/it]Error on item 620: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 439.62 MiB is free. Process 3432158 has 45.54 GiB memory in use. Including non-PyTorch memory, this process has 1.38 GiB memory in use. Of the allocated memory 323.72 MiB is allocated by PyTorch, and 576.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 622: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 167.62 MiB is free. Process 3432158 has 46.63 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 50.06 MiB is allocated by PyTorch, and 11.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 623: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 167.62 MiB is free. Process 3432158 has 46.63 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 624: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 167.62 MiB is free. Process 3432158 has 46.63 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 625: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 167.62 MiB is free. Process 3432158 has 46.63 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 626: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 167.62 MiB is free. Process 3432158 has 46.63 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 627: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 167.62 MiB is free. Process 3432158 has 46.63 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 628: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 167.62 MiB is free. Process 3432158 has 46.63 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 629: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 167.62 MiB is free. Process 3432158 has 46.63 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 630: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 167.62 MiB is free. Process 3432158 has 46.63 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 631: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 167.62 MiB is free. Process 3432158 has 46.63 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 632: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 167.62 MiB is free. Process 3432158 has 46.63 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 633: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 167.62 MiB is free. Process 3432158 has 46.63 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 74%|███████▍  | 636/858 [26:04<17:14,  4.66s/it] 74%|███████▍  | 637/858 [26:04<12:18,  3.34s/it] 74%|███████▍  | 638/858 [26:05<08:49,  2.41s/it] 74%|███████▍  | 639/858 [26:05<06:53,  1.89s/it] 75%|███████▍  | 640/858 [26:05<05:00,  1.38s/it] 75%|███████▍  | 641/858 [26:06<03:42,  1.03s/it] 75%|███████▍  | 642/858 [26:07<03:36,  1.00s/it] 75%|███████▍  | 643/858 [26:07<02:45,  1.30it/s] 75%|███████▌  | 644/858 [26:07<02:05,  1.70it/s] 75%|███████▌  | 645/858 [26:17<11:48,  3.33s/it] 75%|███████▌  | 646/858 [26:17<08:26,  2.39s/it] 75%|███████▌  | 647/858 [26:17<06:04,  1.73s/it] 76%|███████▌  | 648/858 [26:17<04:29,  1.28s/it]Error on item 635: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 535.62 MiB is free. Process 3432158 has 46.25 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 68.97 MiB is allocated by PyTorch, and 11.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 636: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 553.62 MiB is free. Process 3432158 has 46.25 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 637: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 553.62 MiB is free. Process 3432158 has 46.25 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 638: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 517.62 MiB is free. Process 3432158 has 46.25 GiB memory in use. Including non-PyTorch memory, this process has 608.00 MiB memory in use. Of the allocated memory 86.15 MiB is allocated by PyTorch, and 11.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 639: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 553.62 MiB is free. Process 3432158 has 46.25 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 640: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 553.62 MiB is free. Process 3432158 has 46.25 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 641: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 487.62 MiB is free. Process 3432158 has 46.25 GiB memory in use. Including non-PyTorch memory, this process has 638.00 MiB memory in use. Of the allocated memory 116.26 MiB is allocated by PyTorch, and 11.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 642: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 549.62 MiB is free. Process 3432158 has 46.25 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 643: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 549.62 MiB is free. Process 3432158 has 46.25 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 644: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 579.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 68.90 MiB is allocated by PyTorch, and 11.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 645: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 597.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 646: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 597.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 647: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 597.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 76%|███████▌  | 649/858 [26:18<03:21,  1.04it/s] 76%|███████▌  | 650/858 [26:18<02:33,  1.35it/s] 76%|███████▌  | 651/858 [26:18<01:59,  1.73it/s] 76%|███████▌  | 652/858 [26:18<01:35,  2.16it/s] 76%|███████▌  | 653/858 [26:19<01:41,  2.03it/s] 76%|███████▌  | 654/858 [26:19<01:38,  2.06it/s] 76%|███████▋  | 655/858 [26:19<01:20,  2.53it/s] 76%|███████▋  | 656/858 [26:20<01:06,  3.05it/s] 77%|███████▋  | 657/858 [26:20<00:55,  3.60it/s] 77%|███████▋  | 658/858 [26:22<02:58,  1.12it/s] 77%|███████▋  | 659/858 [26:32<11:50,  3.57s/it] 77%|███████▋  | 660/858 [26:41<17:24,  5.27s/it] 77%|███████▋  | 661/858 [26:49<19:31,  5.95s/it] 77%|███████▋  | 662/858 [26:51<15:55,  4.87s/it] 77%|███████▋  | 663/858 [27:00<19:44,  6.08s/it]Error on item 648: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 597.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 649: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 597.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 650: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 597.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 651: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 597.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 652: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 565.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 604.00 MiB memory in use. Of the allocated memory 80.28 MiB is allocated by PyTorch, and 13.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 653: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 565.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 604.00 MiB memory in use. Of the allocated memory 75.24 MiB is allocated by PyTorch, and 18.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 654: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 597.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 655: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 591.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 656: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 591.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 657: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 167.62 MiB is free. Process 3432158 has 46.56 GiB memory in use. Including non-PyTorch memory, this process has 642.00 MiB memory in use. Of the allocated memory 74.17 MiB is allocated by PyTorch, and 57.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 660: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 699.62 MiB is free. Process 3432158 has 45.45 GiB memory in use. Including non-PyTorch memory, this process has 1.21 GiB memory in use. Of the allocated memory 236.44 MiB is allocated by PyTorch, and 497.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 661: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 415.62 MiB is free. Process 3432158 has 46.37 GiB memory in use. Including non-PyTorch memory, this process has 588.00 MiB memory in use. Of the allocated memory 68.59 MiB is allocated by PyTorch, and 9.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 662: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 565.62 MiB is free. Process 3432158 has 46.22 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 69.08 MiB is allocated by PyTorch, and 10.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 77%|███████▋  | 664/858 [27:00<13:58,  4.32s/it] 78%|███████▊  | 665/858 [27:00<09:55,  3.09s/it] 78%|███████▊  | 666/858 [27:01<07:09,  2.24s/it] 78%|███████▊  | 667/858 [27:01<05:51,  1.84s/it] 78%|███████▊  | 668/858 [27:02<04:19,  1.36s/it] 78%|███████▊  | 669/858 [27:02<03:11,  1.01s/it] 78%|███████▊  | 670/858 [27:02<02:23,  1.31it/s] 78%|███████▊  | 671/858 [27:13<11:56,  3.83s/it] 78%|███████▊  | 672/858 [27:13<08:29,  2.74s/it] 78%|███████▊  | 673/858 [27:14<06:07,  1.99s/it] 79%|███████▊  | 674/858 [27:14<04:55,  1.61s/it] 79%|███████▊  | 675/858 [27:15<04:31,  1.48s/it] 79%|███████▉  | 676/858 [27:16<03:16,  1.08s/it]Error on item 663: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 583.62 MiB is free. Process 3432158 has 46.22 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 664: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 583.62 MiB is free. Process 3432158 has 46.22 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 665: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 583.62 MiB is free. Process 3432158 has 46.22 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 666: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 527.62 MiB is free. Process 3432158 has 46.22 GiB memory in use. Including non-PyTorch memory, this process has 628.00 MiB memory in use. Of the allocated memory 106.22 MiB is allocated by PyTorch, and 11.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 667: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 583.62 MiB is free. Process 3432158 has 46.22 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 668: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 577.62 MiB is free. Process 3432158 has 46.23 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 669: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 577.62 MiB is free. Process 3432158 has 46.23 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 670: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 719.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 69.11 MiB is allocated by PyTorch, and 10.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 671: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 737.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 672: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 737.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 673: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 691.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 618.00 MiB memory in use. Of the allocated memory 96.19 MiB is allocated by PyTorch, and 11.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 674: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 659.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 644.00 MiB memory in use. Of the allocated memory 120.61 MiB is allocated by PyTorch, and 13.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 675: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 731.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 79%|███████▉  | 677/858 [27:19<05:07,  1.70s/it] 79%|███████▉  | 678/858 [27:19<03:45,  1.25s/it] 79%|███████▉  | 679/858 [27:19<02:48,  1.06it/s] 79%|███████▉  | 680/858 [27:19<02:06,  1.40it/s] 79%|███████▉  | 681/858 [27:20<01:38,  1.80it/s] 79%|███████▉  | 682/858 [27:20<01:21,  2.17it/s] 80%|███████▉  | 683/858 [27:20<01:07,  2.60it/s] 80%|███████▉  | 684/858 [27:20<00:58,  2.99it/s] 80%|███████▉  | 685/858 [27:21<01:40,  1.72it/s] 80%|███████▉  | 686/858 [27:22<01:21,  2.10it/s] 80%|████████  | 687/858 [27:22<01:05,  2.60it/s] 80%|████████  | 688/858 [27:30<07:42,  2.72s/it] 80%|████████  | 689/858 [27:33<07:49,  2.78s/it] 80%|████████  | 690/858 [27:33<05:37,  2.01s/it]Error on item 676: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 717.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 588.00 MiB memory in use. Of the allocated memory 68.51 MiB is allocated by PyTorch, and 9.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 677: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 733.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 678: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 733.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 679: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 733.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 680: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 733.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 681: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 733.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 682: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 733.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 683: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 733.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 684: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 661.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 644.00 MiB memory in use. Of the allocated memory 120.61 MiB is allocated by PyTorch, and 13.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 685: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 727.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 686: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 727.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 688: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 723.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 584.00 MiB memory in use. Of the allocated memory 68.35 MiB is allocated by PyTorch, and 5.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 689: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 735.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 81%|████████  | 691/858 [27:34<04:25,  1.59s/it] 81%|████████  | 692/858 [27:34<03:13,  1.17s/it] 81%|████████  | 693/858 [27:34<02:44,  1.00it/s] 81%|████████  | 694/858 [27:35<02:15,  1.21it/s] 81%|████████  | 695/858 [27:49<12:48,  4.71s/it] 81%|████████  | 696/858 [27:53<12:43,  4.71s/it] 81%|████████  | 697/858 [27:54<09:22,  3.49s/it] 81%|████████▏ | 698/858 [27:54<06:41,  2.51s/it] 81%|████████▏ | 699/858 [27:54<04:49,  1.82s/it] 82%|████████▏ | 700/858 [27:55<03:32,  1.35s/it] 82%|████████▏ | 701/858 [27:55<02:37,  1.00s/it] 82%|████████▏ | 702/858 [27:55<01:58,  1.32it/s] 82%|████████▏ | 703/858 [27:55<01:33,  1.67it/s] 82%|████████▏ | 704/858 [27:56<01:14,  2.07it/s]Error on item 690: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 699.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 608.00 MiB memory in use. Of the allocated memory 86.15 MiB is allocated by PyTorch, and 11.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 691: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 735.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 692: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 703.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 604.00 MiB memory in use. Of the allocated memory 80.28 MiB is allocated by PyTorch, and 13.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 693: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 703.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 604.00 MiB memory in use. Of the allocated memory 70.20 MiB is allocated by PyTorch, and 23.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 695: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 613.62 MiB is free. Process 3432158 has 46.17 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 69.01 MiB is allocated by PyTorch, and 10.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 696: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 589.62 MiB is free. Process 3432158 has 46.17 GiB memory in use. Including non-PyTorch memory, this process has 614.00 MiB memory in use. Of the allocated memory 90.37 MiB is allocated by PyTorch, and 13.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 697: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 631.62 MiB is free. Process 3432158 has 46.17 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 698: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 631.62 MiB is free. Process 3432158 has 46.17 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 699: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 631.62 MiB is free. Process 3432158 has 46.17 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 700: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 631.62 MiB is free. Process 3432158 has 46.17 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 701: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 631.62 MiB is free. Process 3432158 has 46.17 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 702: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 631.62 MiB is free. Process 3432158 has 46.17 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 703: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 631.62 MiB is free. Process 3432158 has 46.17 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 82%|████████▏ | 705/858 [27:56<01:01,  2.47it/s] 82%|████████▏ | 706/858 [27:56<00:52,  2.90it/s] 82%|████████▏ | 707/858 [27:56<00:44,  3.38it/s] 83%|████████▎ | 708/858 [27:56<00:39,  3.79it/s] 83%|████████▎ | 709/858 [27:56<00:35,  4.23it/s] 83%|████████▎ | 710/858 [27:57<00:39,  3.77it/s] 83%|████████▎ | 711/858 [28:00<02:51,  1.16s/it] 83%|████████▎ | 712/858 [28:00<02:07,  1.15it/s] 83%|████████▎ | 713/858 [28:00<01:37,  1.48it/s] 83%|████████▎ | 714/858 [28:01<01:18,  1.85it/s] 83%|████████▎ | 715/858 [28:01<01:02,  2.28it/s] 83%|████████▎ | 716/858 [28:01<00:51,  2.76it/s] 84%|████████▎ | 717/858 [28:01<00:44,  3.13it/s]Error on item 704: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 631.62 MiB is free. Process 3432158 has 46.17 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 705: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 631.62 MiB is free. Process 3432158 has 46.17 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 706: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 631.62 MiB is free. Process 3432158 has 46.17 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 707: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 631.62 MiB is free. Process 3432158 has 46.17 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 708: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 631.62 MiB is free. Process 3432158 has 46.17 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 709: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 549.62 MiB is free. Process 3432158 has 46.51 GiB memory in use. Including non-PyTorch memory, this process has 588.00 MiB memory in use. Of the allocated memory 66.08 MiB is allocated by PyTorch, and 11.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 710: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 729.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 588.00 MiB memory in use. Of the allocated memory 68.71 MiB is allocated by PyTorch, and 9.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 711: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 745.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 712: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 745.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 713: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 745.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 714: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 745.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 715: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 745.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 716: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 745.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 84%|████████▎ | 718/858 [28:02<00:40,  3.44it/s] 84%|████████▍ | 719/858 [28:03<01:18,  1.78it/s] 84%|████████▍ | 720/858 [28:03<01:01,  2.24it/s] 84%|████████▍ | 721/858 [28:03<00:50,  2.71it/s] 84%|████████▍ | 722/858 [28:12<06:41,  2.95s/it] 84%|████████▍ | 723/858 [28:14<06:09,  2.73s/it] 84%|████████▍ | 724/858 [28:15<04:30,  2.02s/it] 84%|████████▍ | 725/858 [28:15<03:34,  1.62s/it] 85%|████████▍ | 726/858 [28:16<02:44,  1.25s/it] 85%|████████▍ | 727/858 [28:19<04:21,  1.99s/it] 85%|████████▍ | 728/858 [28:27<07:58,  3.68s/it] 85%|████████▍ | 729/858 [28:27<05:39,  2.63s/it] 85%|████████▌ | 730/858 [28:34<08:31,  4.00s/it] 85%|████████▌ | 731/858 [28:37<07:51,  3.71s/it] 85%|████████▌ | 732/858 [28:45<10:04,  4.80s/it] 85%|████████▌ | 733/858 [28:49<09:32,  4.58s/it]Error on item 717: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 745.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 718: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 669.62 MiB is free. Process 3432158 has 46.06 GiB memory in use. Including non-PyTorch memory, this process has 648.00 MiB memory in use. Of the allocated memory 126.29 MiB is allocated by PyTorch, and 11.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 719: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 737.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 720: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 395.62 MiB is free. Process 3432158 has 46.01 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 722: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 603.62 MiB is free. Process 3432158 has 46.05 GiB memory in use. Including non-PyTorch memory, this process has 724.00 MiB memory in use. Of the allocated memory 201.28 MiB is allocated by PyTorch, and 12.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 723: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 161.62 MiB is free. Process 3432158 has 46.05 GiB memory in use. Including non-PyTorch memory, this process has 1.14 GiB memory in use. Of the allocated memory 62.18 MiB is allocated by PyTorch, and 593.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 724: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 161.62 MiB is free. Process 3432158 has 46.05 GiB memory in use. Including non-PyTorch memory, this process has 1.14 GiB memory in use. Of the allocated memory 85.32 MiB is allocated by PyTorch, and 570.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 725: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 161.62 MiB is free. Process 3432158 has 46.05 GiB memory in use. Including non-PyTorch memory, this process has 1.14 GiB memory in use. Of the allocated memory 62.18 MiB is allocated by PyTorch, and 593.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 726: CUDA out of memory. Tried to allocate 132.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 163.62 MiB is free. Process 3432158 has 45.54 GiB memory in use. Including non-PyTorch memory, this process has 1.44 GiB memory in use. Of the allocated memory 878.08 MiB is allocated by PyTorch, and 85.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 727: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 479.62 MiB is free. Process 3432158 has 46.30 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 68.94 MiB is allocated by PyTorch, and 11.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 728: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 357.62 MiB is free. Process 3432158 has 46.44 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 730: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 751.62 MiB is free. Process 3432158 has 46.04 GiB memory in use. Including non-PyTorch memory, this process has 588.00 MiB memory in use. Of the allocated memory 68.51 MiB is allocated by PyTorch, and 9.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 732: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 575.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 68.87 MiB is allocated by PyTorch, and 11.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 86%|████████▌ | 734/858 [28:49<06:46,  3.28s/it] 86%|████████▌ | 735/858 [28:49<04:48,  2.35s/it] 86%|████████▌ | 736/858 [28:49<03:27,  1.70s/it] 86%|████████▌ | 737/858 [28:50<02:30,  1.24s/it] 86%|████████▌ | 738/858 [28:51<02:34,  1.29s/it] 86%|████████▌ | 739/858 [28:51<01:54,  1.04it/s] 86%|████████▌ | 740/858 [29:03<08:01,  4.08s/it] 86%|████████▋ | 741/858 [29:06<07:43,  3.96s/it] 86%|████████▋ | 742/858 [29:09<06:54,  3.57s/it] 87%|████████▋ | 743/858 [29:09<04:55,  2.57s/it] 87%|████████▋ | 744/858 [29:09<03:31,  1.85s/it] 87%|████████▋ | 745/858 [29:10<02:39,  1.41s/it] 87%|████████▋ | 746/858 [29:10<01:58,  1.05s/it]Error on item 733: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 593.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 734: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 593.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 735: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 593.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 736: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 593.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 737: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 497.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 668.00 MiB memory in use. Of the allocated memory 146.36 MiB is allocated by PyTorch, and 11.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 738: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 593.62 MiB is free. Process 3432158 has 46.21 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 739: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 651.62 MiB is free. Process 3432158 has 45.50 GiB memory in use. Including non-PyTorch memory, this process has 1.22 GiB memory in use. Of the allocated memory 236.58 MiB is allocated by PyTorch, and 499.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 740: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 201.62 MiB is free. Process 3432158 has 46.58 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 68.90 MiB is allocated by PyTorch, and 11.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 741: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 611.62 MiB is free. Process 3432158 has 46.18 GiB memory in use. Including non-PyTorch memory, this process has 584.00 MiB memory in use. Of the allocated memory 67.92 MiB is allocated by PyTorch, and 6.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 742: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 623.62 MiB is free. Process 3432158 has 46.18 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 743: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 623.62 MiB is free. Process 3432158 has 46.18 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 744: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 601.62 MiB is free. Process 3432158 has 46.18 GiB memory in use. Including non-PyTorch memory, this process has 594.00 MiB memory in use. Of the allocated memory 70.20 MiB is allocated by PyTorch, and 13.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 745: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 623.62 MiB is free. Process 3432158 has 46.18 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 87%|████████▋ | 747/858 [29:10<01:28,  1.25it/s] 87%|████████▋ | 748/858 [29:10<01:08,  1.61it/s] 87%|████████▋ | 749/858 [29:11<01:17,  1.41it/s] 87%|████████▋ | 750/858 [29:12<01:01,  1.76it/s] 88%|████████▊ | 751/858 [29:12<00:49,  2.18it/s] 88%|████████▊ | 752/858 [29:25<07:29,  4.24s/it] 88%|████████▊ | 753/858 [29:31<08:21,  4.78s/it] 88%|████████▊ | 754/858 [29:31<05:55,  3.41s/it] 88%|████████▊ | 755/858 [29:32<04:41,  2.73s/it] 88%|████████▊ | 756/858 [29:32<03:22,  1.98s/it] 88%|████████▊ | 757/858 [29:33<02:27,  1.46s/it] 88%|████████▊ | 758/858 [29:33<01:47,  1.08s/it] 88%|████████▊ | 759/858 [29:33<01:20,  1.23it/s] 89%|████████▊ | 760/858 [29:33<01:02,  1.58it/s]Error on item 746: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 623.62 MiB is free. Process 3432158 has 46.18 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 747: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 623.62 MiB is free. Process 3432158 has 46.18 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 748: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 561.62 MiB is free. Process 3432158 has 46.18 GiB memory in use. Including non-PyTorch memory, this process has 634.00 MiB memory in use. Of the allocated memory 110.53 MiB is allocated by PyTorch, and 13.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 749: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 623.62 MiB is free. Process 3432158 has 46.18 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 750: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 623.62 MiB is free. Process 3432158 has 46.18 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 752: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 723.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 588.00 MiB memory in use. Of the allocated memory 68.87 MiB is allocated by PyTorch, and 9.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 753: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 739.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 754: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 673.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 638.00 MiB memory in use. Of the allocated memory 116.26 MiB is allocated by PyTorch, and 11.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 755: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 739.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 756: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 739.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 757: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 739.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 758: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 739.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 759: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 739.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 89%|████████▊ | 761/858 [29:34<00:49,  1.97it/s] 89%|████████▉ | 762/858 [29:34<00:39,  2.41it/s] 89%|████████▉ | 763/858 [29:34<00:32,  2.90it/s] 89%|████████▉ | 764/858 [29:37<01:44,  1.11s/it] 89%|████████▉ | 765/858 [29:37<01:26,  1.07it/s] 89%|████████▉ | 766/858 [29:38<01:10,  1.31it/s] 89%|████████▉ | 767/858 [29:38<00:58,  1.55it/s] 90%|████████▉ | 768/858 [29:38<00:48,  1.85it/s] 90%|████████▉ | 769/858 [29:39<00:43,  2.03it/s] 90%|████████▉ | 770/858 [29:39<00:39,  2.24it/s] 90%|████████▉ | 771/858 [29:39<00:36,  2.38it/s] 90%|████████▉ | 772/858 [29:40<00:35,  2.42it/s] 90%|█████████ | 773/858 [29:40<00:34,  2.47it/s] 90%|█████████ | 774/858 [29:47<03:22,  2.41s/it]Error on item 760: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 739.62 MiB is free. Process 3432158 has 46.07 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 761: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 731.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 762: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 731.62 MiB is free. Process 3432158 has 46.08 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 763: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 741.62 MiB is free. Process 3432158 has 46.05 GiB memory in use. Including non-PyTorch memory, this process has 588.00 MiB memory in use. Of the allocated memory 68.59 MiB is allocated by PyTorch, and 9.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 764: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 731.62 MiB is free. Process 3432158 has 46.05 GiB memory in use. Including non-PyTorch memory, this process has 598.00 MiB memory in use. Of the allocated memory 76.12 MiB is allocated by PyTorch, and 11.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 765: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 161.62 MiB is free. Process 3432158 has 46.05 GiB memory in use. Including non-PyTorch memory, this process has 1.14 GiB memory in use. Of the allocated memory 80.83 MiB is allocated by PyTorch, and 577.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 766: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 161.62 MiB is free. Process 3432158 has 46.05 GiB memory in use. Including non-PyTorch memory, this process has 1.14 GiB memory in use. Of the allocated memory 80.81 MiB is allocated by PyTorch, and 577.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 767: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 163.62 MiB is free. Process 3432158 has 46.05 GiB memory in use. Including non-PyTorch memory, this process has 1.14 GiB memory in use. Of the allocated memory 60.11 MiB is allocated by PyTorch, and 595.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 768: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 161.62 MiB is free. Process 3432158 has 46.05 GiB memory in use. Including non-PyTorch memory, this process has 1.14 GiB memory in use. Of the allocated memory 80.85 MiB is allocated by PyTorch, and 577.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 769: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 161.62 MiB is free. Process 3432158 has 46.05 GiB memory in use. Including non-PyTorch memory, this process has 1.14 GiB memory in use. Of the allocated memory 80.82 MiB is allocated by PyTorch, and 577.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 770: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 161.62 MiB is free. Process 3432158 has 46.05 GiB memory in use. Including non-PyTorch memory, this process has 1.14 GiB memory in use. Of the allocated memory 80.84 MiB is allocated by PyTorch, and 577.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 771: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 161.62 MiB is free. Process 3432158 has 46.05 GiB memory in use. Including non-PyTorch memory, this process has 1.14 GiB memory in use. Of the allocated memory 80.83 MiB is allocated by PyTorch, and 577.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 772: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 161.62 MiB is free. Process 3432158 has 46.05 GiB memory in use. Including non-PyTorch memory, this process has 1.14 GiB memory in use. Of the allocated memory 80.86 MiB is allocated by PyTorch, and 577.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 90%|█████████ | 775/858 [29:51<04:03,  2.93s/it] 90%|█████████ | 776/858 [29:52<03:08,  2.30s/it] 91%|█████████ | 777/858 [29:53<02:22,  1.76s/it] 91%|█████████ | 778/858 [29:53<01:44,  1.30s/it] 91%|█████████ | 779/858 [29:54<01:34,  1.20s/it] 91%|█████████ | 780/858 [30:05<05:21,  4.13s/it] 91%|█████████ | 781/858 [30:13<06:46,  5.28s/it] 91%|█████████ | 782/858 [30:20<07:21,  5.81s/it] 91%|█████████▏| 783/858 [30:20<05:10,  4.14s/it] 91%|█████████▏| 784/858 [30:20<03:39,  2.96s/it] 91%|█████████▏| 785/858 [30:21<02:35,  2.13s/it] 92%|█████████▏| 786/858 [30:21<01:52,  1.56s/it] 92%|█████████▏| 787/858 [30:21<01:22,  1.16s/it] 92%|█████████▏| 788/858 [30:23<01:28,  1.26s/it]Error on item 774: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 701.62 MiB is free. Process 3432158 has 46.09 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 68.97 MiB is allocated by PyTorch, and 11.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 775: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 673.62 MiB is free. Process 3432158 has 46.09 GiB memory in use. Including non-PyTorch memory, this process has 618.00 MiB memory in use. Of the allocated memory 96.19 MiB is allocated by PyTorch, and 11.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 776: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 673.62 MiB is free. Process 3432158 has 46.09 GiB memory in use. Including non-PyTorch memory, this process has 618.00 MiB memory in use. Of the allocated memory 80.28 MiB is allocated by PyTorch, and 27.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 777: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 719.62 MiB is free. Process 3432158 has 46.09 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 778: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 315.62 MiB is free. Process 3432158 has 46.27 GiB memory in use. Including non-PyTorch memory, this process has 628.00 MiB memory in use. Of the allocated memory 106.22 MiB is allocated by PyTorch, and 11.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 779: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 195.62 MiB is free. Process 3432158 has 45.78 GiB memory in use. Including non-PyTorch memory, this process has 1.38 GiB memory in use. Of the allocated memory 353.94 MiB is allocated by PyTorch, and 552.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 781: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 213.62 MiB is free. Process 3432158 has 46.53 GiB memory in use. Including non-PyTorch memory, this process has 630.00 MiB memory in use. Of the allocated memory 99.69 MiB is allocated by PyTorch, and 20.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 782: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 271.62 MiB is free. Process 3432158 has 46.53 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 783: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 271.62 MiB is free. Process 3432158 has 46.53 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 784: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 271.62 MiB is free. Process 3432158 has 46.53 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 785: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 271.62 MiB is free. Process 3432158 has 46.53 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 786: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 271.62 MiB is free. Process 3432158 has 46.53 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 787: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 163.62 MiB is free. Process 3432158 has 46.53 GiB memory in use. Including non-PyTorch memory, this process has 674.00 MiB memory in use. Of the allocated memory 150.87 MiB is allocated by PyTorch, and 13.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 92%|█████████▏| 789/858 [30:25<02:00,  1.75s/it] 92%|█████████▏| 790/858 [30:26<01:27,  1.28s/it] 92%|█████████▏| 791/858 [30:26<01:04,  1.04it/s] 92%|█████████▏| 792/858 [30:26<00:48,  1.35it/s] 92%|█████████▏| 793/858 [30:26<00:37,  1.75it/s] 93%|█████████▎| 794/858 [30:26<00:29,  2.15it/s] 93%|█████████▎| 795/858 [30:27<00:24,  2.59it/s] 93%|█████████▎| 796/858 [30:27<00:20,  3.00it/s] 93%|█████████▎| 797/858 [30:28<00:41,  1.46it/s] 93%|█████████▎| 798/858 [30:29<00:32,  1.82it/s] 93%|█████████▎| 799/858 [30:29<00:26,  2.19it/s] 93%|█████████▎| 800/858 [30:38<03:04,  3.18s/it] 93%|█████████▎| 801/858 [30:40<02:29,  2.61s/it] 93%|█████████▎| 802/858 [30:40<01:45,  1.89s/it]Error on item 788: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 429.62 MiB is free. Process 3432158 has 46.36 GiB memory in use. Including non-PyTorch memory, this process has 588.00 MiB memory in use. Of the allocated memory 68.47 MiB is allocated by PyTorch, and 9.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 789: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 445.62 MiB is free. Process 3432158 has 46.36 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 790: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 445.62 MiB is free. Process 3432158 has 46.36 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 791: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 445.62 MiB is free. Process 3432158 has 46.36 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 792: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 445.62 MiB is free. Process 3432158 has 46.36 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 793: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 445.62 MiB is free. Process 3432158 has 46.36 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 794: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 445.62 MiB is free. Process 3432158 has 46.36 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 795: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 445.62 MiB is free. Process 3432158 has 46.36 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 796: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 343.62 MiB is free. Process 3432158 has 46.36 GiB memory in use. Including non-PyTorch memory, this process has 674.00 MiB memory in use. Of the allocated memory 150.87 MiB is allocated by PyTorch, and 13.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 797: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 443.62 MiB is free. Process 3432158 has 46.36 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 798: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 459.62 MiB is free. Process 3432158 has 46.28 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 800: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 515.62 MiB is free. Process 3432158 has 46.20 GiB memory in use. Including non-PyTorch memory, this process has 664.00 MiB memory in use. Of the allocated memory 140.78 MiB is allocated by PyTorch, and 13.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 801: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 607.62 MiB is free. Process 3432158 has 46.20 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 94%|█████████▎| 803/858 [30:41<01:23,  1.52s/it] 94%|█████████▎| 804/858 [30:44<02:00,  2.23s/it] 94%|█████████▍| 805/858 [30:53<03:45,  4.26s/it] 94%|█████████▍| 806/858 [31:04<05:15,  6.06s/it] 94%|█████████▍| 807/858 [31:14<06:09,  7.24s/it] 94%|█████████▍| 808/858 [31:20<05:43,  6.87s/it] 94%|█████████▍| 809/858 [31:29<06:12,  7.60s/it] 94%|█████████▍| 810/858 [31:38<06:30,  8.14s/it] 95%|█████████▍| 811/858 [31:42<05:25,  6.93s/it] 95%|█████████▍| 812/858 [31:43<03:47,  4.95s/it] 95%|█████████▍| 813/858 [31:43<02:39,  3.55s/it] 95%|█████████▍| 814/858 [31:44<01:56,  2.65s/it] 95%|█████████▍| 815/858 [31:44<01:23,  1.95s/it] 95%|█████████▌| 816/858 [31:44<01:01,  1.46s/it] 95%|█████████▌| 817/858 [31:45<00:45,  1.12s/it] 95%|█████████▌| 818/858 [31:45<00:33,  1.19it/s] 95%|█████████▌| 819/858 [31:45<00:25,  1.53it/s]Error on item 802: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 571.62 MiB is free. Process 3432158 has 46.20 GiB memory in use. Including non-PyTorch memory, this process has 608.00 MiB memory in use. Of the allocated memory 86.15 MiB is allocated by PyTorch, and 11.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 803: CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 271.62 MiB is free. Process 3432158 has 45.06 GiB memory in use. Including non-PyTorch memory, this process has 1.79 GiB memory in use. Of the allocated memory 1.14 GiB is allocated by PyTorch, and 152.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 804: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 749.62 MiB is free. Process 3432158 has 46.04 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 69.08 MiB is allocated by PyTorch, and 10.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 808: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 753.62 MiB is free. Process 3432158 has 46.04 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 68.87 MiB is allocated by PyTorch, and 11.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 810: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 693.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 69.01 MiB is allocated by PyTorch, and 10.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 811: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 711.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 812: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 711.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 813: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 695.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 588.00 MiB memory in use. Of the allocated memory 66.08 MiB is allocated by PyTorch, and 11.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 814: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 711.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 815: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 711.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 816: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 711.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 817: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 711.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 818: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 705.62 MiB is free. Process 3432158 has 46.10 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 96%|█████████▌| 820/858 [31:55<02:08,  3.39s/it] 96%|█████████▌| 821/858 [31:55<01:30,  2.44s/it] 96%|█████████▌| 822/858 [31:55<01:03,  1.77s/it] 96%|█████████▌| 823/858 [31:55<00:45,  1.30s/it] 96%|█████████▌| 824/858 [31:56<00:33,  1.03it/s] 96%|█████████▌| 825/858 [31:56<00:24,  1.35it/s] 96%|█████████▋| 826/858 [31:56<00:18,  1.72it/s] 96%|█████████▋| 827/858 [31:56<00:14,  2.13it/s] 97%|█████████▋| 828/858 [31:56<00:11,  2.57it/s] 97%|█████████▋| 829/858 [31:57<00:09,  3.03it/s] 97%|█████████▋| 830/858 [31:58<00:15,  1.78it/s] 97%|█████████▋| 831/858 [31:58<00:13,  2.04it/s] 97%|█████████▋| 832/858 [32:01<00:29,  1.13s/it]Error on item 819: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 505.62 MiB is free. Process 3432158 has 46.28 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 68.90 MiB is allocated by PyTorch, and 11.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 820: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 523.62 MiB is free. Process 3432158 has 46.28 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 821: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 523.62 MiB is free. Process 3432158 has 46.28 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 822: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 523.62 MiB is free. Process 3432158 has 46.28 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 823: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 523.62 MiB is free. Process 3432158 has 46.28 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 824: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 523.62 MiB is free. Process 3432158 has 46.28 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 825: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 523.62 MiB is free. Process 3432158 has 46.28 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 826: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 523.62 MiB is free. Process 3432158 has 46.28 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 827: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 523.62 MiB is free. Process 3432158 has 46.28 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 828: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 523.62 MiB is free. Process 3432158 has 46.28 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 829: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 467.62 MiB is free. Process 3432158 has 46.28 GiB memory in use. Including non-PyTorch memory, this process has 624.00 MiB memory in use. Of the allocated memory 100.45 MiB is allocated by PyTorch, and 13.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 830: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 519.62 MiB is free. Process 3432158 has 46.38 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 831: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 665.62 MiB is free. Process 3432158 has 46.03 GiB memory in use. Including non-PyTorch memory, this process has 588.00 MiB memory in use. Of the allocated memory 68.63 MiB is allocated by PyTorch, and 9.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 97%|█████████▋| 833/858 [32:08<01:17,  3.09s/it] 97%|█████████▋| 834/858 [32:09<00:53,  2.23s/it] 97%|█████████▋| 835/858 [32:09<00:37,  1.64s/it] 97%|█████████▋| 836/858 [32:09<00:26,  1.21s/it] 98%|█████████▊| 837/858 [32:09<00:19,  1.10it/s] 98%|█████████▊| 838/858 [32:09<00:14,  1.43it/s] 98%|█████████▊| 839/858 [32:11<00:19,  1.03s/it] 98%|█████████▊| 840/858 [32:11<00:14,  1.28it/s] 98%|█████████▊| 841/858 [32:12<00:10,  1.70it/s] 98%|█████████▊| 842/858 [32:15<00:23,  1.45s/it] 98%|█████████▊| 843/858 [32:15<00:16,  1.09s/it] 98%|█████████▊| 844/858 [32:15<00:11,  1.22it/s] 98%|█████████▊| 845/858 [32:16<00:08,  1.59it/s]Error on item 832: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 189.62 MiB is free. Process 3432158 has 46.59 GiB memory in use. Including non-PyTorch memory, this process has 590.00 MiB memory in use. Of the allocated memory 68.98 MiB is allocated by PyTorch, and 11.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 833: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 207.62 MiB is free. Process 3432158 has 46.59 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 834: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 195.62 MiB is free. Process 3432158 has 46.59 GiB memory in use. Including non-PyTorch memory, this process has 584.00 MiB memory in use. Of the allocated memory 60.11 MiB is allocated by PyTorch, and 13.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 835: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 207.62 MiB is free. Process 3432158 has 46.59 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 836: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 207.62 MiB is free. Process 3432158 has 46.59 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 837: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 207.62 MiB is free. Process 3432158 has 46.59 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 838: CUDA out of memory. Tried to allocate 132.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 207.62 MiB is free. Process 3432158 has 46.59 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 50.14 MiB is allocated by PyTorch, and 11.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 839: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 199.62 MiB is free. Process 3432158 has 46.60 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 840: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 199.62 MiB is free. Process 3432158 has 46.60 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 841: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 685.62 MiB is free. Process 3432158 has 46.11 GiB memory in use. Including non-PyTorch memory, this process has 588.00 MiB memory in use. Of the allocated memory 68.71 MiB is allocated by PyTorch, and 9.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 842: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 701.62 MiB is free. Process 3432158 has 46.11 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 843: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 701.62 MiB is free. Process 3432158 has 46.11 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 844: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 701.62 MiB is free. Process 3432158 has 46.11 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 99%|█████████▊| 846/858 [32:16<00:05,  2.01it/s] 99%|█████████▊| 847/858 [32:16<00:05,  2.09it/s] 99%|█████████▉| 848/858 [32:17<00:04,  2.46it/s] 99%|█████████▉| 849/858 [32:17<00:03,  2.87it/s] 99%|█████████▉| 850/858 [32:26<00:24,  3.07s/it] 99%|█████████▉| 851/858 [32:30<00:23,  3.42s/it] 99%|█████████▉| 852/858 [32:31<00:14,  2.47s/it] 99%|█████████▉| 853/858 [32:31<00:08,  1.79s/it]100%|█████████▉| 854/858 [32:31<00:05,  1.31s/it]100%|█████████▉| 855/858 [32:31<00:02,  1.02it/s]100%|█████████▉| 856/858 [32:31<00:01,  1.32it/s]100%|█████████▉| 857/858 [32:32<00:00,  1.69it/s]100%|██████████| 858/858 [32:32<00:00,  2.04it/s]100%|██████████| 858/858 [32:32<00:00,  2.28s/it]
Error on item 845: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 701.62 MiB is free. Process 3432158 has 46.11 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 846: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 679.62 MiB is free. Process 3432158 has 46.11 GiB memory in use. Including non-PyTorch memory, this process has 594.00 MiB memory in use. Of the allocated memory 70.20 MiB is allocated by PyTorch, and 13.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 847: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 701.62 MiB is free. Process 3432158 has 46.11 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 848: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 701.62 MiB is free. Process 3432158 has 46.11 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 849: CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 307.62 MiB is free. Process 3432158 has 45.54 GiB memory in use. Including non-PyTorch memory, this process has 1.44 GiB memory in use. Of the allocated memory 903.85 MiB is allocated by PyTorch, and 56.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 850: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 661.62 MiB is free. Process 3432158 has 46.13 GiB memory in use. Including non-PyTorch memory, this process has 588.00 MiB memory in use. Of the allocated memory 68.80 MiB is allocated by PyTorch, and 9.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 851: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 677.62 MiB is free. Process 3432158 has 46.13 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 852: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 677.62 MiB is free. Process 3432158 has 46.13 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 853: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 677.62 MiB is free. Process 3432158 has 46.13 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 854: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 677.62 MiB is free. Process 3432158 has 46.13 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 855: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 677.62 MiB is free. Process 3432158 has 46.13 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 856: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 677.62 MiB is free. Process 3432158 has 46.13 GiB memory in use. Including non-PyTorch memory, this process has 572.00 MiB memory in use. Of the allocated memory 55.07 MiB is allocated by PyTorch, and 6.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error on item 857: CUDA out of memory. Tried to allocate 594.00 MiB. GPU 0 has a total capacity of 47.38 GiB of which 665.62 MiB is free. Process 3432158 has 46.13 GiB memory in use. Including non-PyTorch memory, this process has 584.00 MiB memory in use. Of the allocated memory 60.11 MiB is allocated by PyTorch, and 13.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Benchmark Evaluation Results:
----------------------------------------------------------
Person perspective - Scene Simulation Relative Direction: 10/159 = 6.29%
Person perspective - Relative Direction: 11/123 = 8.94%
Camera perspective - Object View Orientation: 11/173 = 6.36%
Person perspective - Object View Orientation: 15/142 = 10.56%
Camera perspective - Relative Direction: 22/261 = 8.43%
----------------------------------------------------------
Accuracy of mvsm_lora_64_merged: 8.04% (69/858)
----------------------------------------------------------
Result saved to result/mvsm_lora_64_merged/result_mvsm_lora_64_merged.csv
