import os
import sys

# ==========================================
# 1. GPU ÏÑ§Ï†ï (3Î≤à GPU ÏÇ¨Ïö©)
# ==========================================
os.environ["CUDA_VISIBLE_DEVICES"] = "3"
print(f"üñ•Ô∏è GPU Setting: CUDA_VISIBLE_DEVICES = {os.environ['CUDA_VISIBLE_DEVICES']}")

import cv2
import torch
import torch.nn.functional as F
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image
from tqdm import tqdm
from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor

# qwen_vl_utils ÎùºÏù¥Î∏åÎü¨Î¶¨ Ï≤¥ÌÅ¨ Î∞è Î°úÎìú
try:
    from qwen_vl_utils import process_vision_info
except ImportError:
    print("‚ö†Ô∏è 'qwen_vl_utils' ÎùºÏù¥Î∏åÎü¨Î¶¨Í∞Ä ÏóÜÏäµÎãàÎã§. ÏÑ§ÏπòÎ•º ÏãúÎèÑÌï©ÎãàÎã§...")
    import subprocess
    subprocess.check_call([sys.executable, "-m", "pip", "install", "qwen-vl-utils"])
    from qwen_vl_utils import process_vision_info
    print("‚úÖ 'qwen-vl-utils' ÏÑ§Ïπò Î∞è Î°úÎìú ÏôÑÎ£å!")

# ==========================================
# 2. Î™®Îç∏ Î°úÎìú
# ==========================================
print("üöÄ Loading Model on GPU 3...")
try:
    model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
        "Qwen/Qwen2.5-VL-7B-Instruct", 
        torch_dtype="auto", 
        device_map="auto"
    )
    processor = AutoProcessor.from_pretrained("Qwen/Qwen2.5-VL-7B-Instruct")
    print("‚úÖ Model Loaded Successfully!")
except Exception as e:
    print(f"‚ùå Model Load Failed: {e}")
    sys.exit(1)

# ÌÉÄÍ≤ü Îã®Ïñ¥ ÏÑ§Ï†ï
target_words = ["Left", "Right", "Center"]
target_ids = [processor.tokenizer.encode(w, add_special_tokens=False)[0] for w in target_words]
target_ids_tensor = torch.tensor(target_ids).to("cuda")

# ==========================================
# 3. ÌïµÏã¨ ÏïåÍ≥†Î¶¨Ï¶ò (Entropy & Adaptive Alpha)
# ==========================================
def calculate_entropy(probs):
    return -torch.sum(probs * torch.log(probs + 1e-9), dim=-1)

def get_adaptive_alpha(current_probs, sensitivity=5.0):
    entropy = calculate_entropy(current_probs)
    # Threshold 0.7 Í∏∞Ï§Ä Sigmoid Ï†ÅÏö©
    adaptive_alpha = torch.sigmoid(sensitivity * (entropy - 0.7)).item()
    return np.clip(adaptive_alpha, 0.1, 0.9)

def apply_smoothing(current_logits, history_probs, method="fixed", alpha=0.6):
    current_probs = F.softmax(current_logits, dim=-1)
    if history_probs is None:
        return current_probs, 0.0
    
    if method == "fixed":
        final_alpha = alpha
    elif method == "adaptive":
        final_alpha = get_adaptive_alpha(current_probs)
        
    smoothed_probs = (1 - final_alpha) * current_probs + final_alpha * history_probs
    return smoothed_probs, final_alpha

# ==========================================
# 4. Îç∞Ïù¥ÌÑ∞ ÏàòÏßë (Full Scan)
# ==========================================
VIDEO_PATH = "/nas_data2/seungwoo/dataset/epic_data/EPIC-KITCHENS/P01/videos/P01_01.MP4"
STRIDE = 5
prompt_text = "Where is the sink? Answer with one word: Left, Right, or Center."

# ÌååÏùº Ï°¥Ïû¨ ÌôïÏù∏
if not os.path.exists(VIDEO_PATH):
    print(f"‚ùå Error: ÌååÏùºÏù¥ Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏäµÎãàÎã§: {VIDEO_PATH}")
    sys.exit(1)

results_log = []
history_adaptive = None

cap = cv2.VideoCapture(VIDEO_PATH)
total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
fps = cap.get(cv2.CAP_PROP_FPS)
if fps == 0: fps = 30.0

print(f"üé¨ Starting Stress Test on {VIDEO_PATH}")
print(f"   - Total Frames: {total_frames}")
print(f"   - Stride: {STRIDE}")

frame_idx = 0
pbar = tqdm(total=total_frames)

while cap.isOpened():
    ret, frame = cap.read()
    if not ret: break
    
    # Stride Ï†ÅÏö©
    if frame_idx % STRIDE != 0:
        frame_idx += 1
        pbar.update(1)
        continue
        
    # Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨
    pil_img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
    messages = [{"role": "user", "content": [{"type": "image", "image": pil_img}, {"type": "text", "text": prompt_text}]}]
    
    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
    image_inputs, video_inputs = process_vision_info(messages)
    inputs = processor(text=[text], images=image_inputs, videos=video_inputs, padding=True, return_tensors="pt").to("cuda")
    
    # --- [A] Baseline (Greedy) & [B] Ours (Adaptive) ---
    with torch.no_grad():
        outputs = model.generate(**inputs, max_new_tokens=1, output_scores=True, return_dict_in_generate=True)
        
    logits = outputs.scores[0][0][target_ids_tensor]
    
    # Baseline Ï≤òÎ¶¨
    prob_base = F.softmax(logits, dim=-1)
    pred_base_idx = torch.argmax(prob_base).item()
    
    # Ours Ï≤òÎ¶¨
    prob_adapt, used_alpha = apply_smoothing(logits, history_adaptive, method="adaptive")
    history_adaptive = prob_adapt
    pred_adapt_idx = torch.argmax(prob_adapt).item()
    
    # --- [C] Baseline (Random Sampling) - "The Chaos Mode" ---
    # Î™®Îç∏Ïùò Î≥∏ÏßàÏ†Å Î∂àÏïàÏ†ïÏÑ±ÏùÑ Î≥¥Í∏∞ ÏúÑÌï¥ Random Sampling ÏàòÌñâ
    with torch.no_grad():
        outputs_rand = model.generate(
            **inputs, 
            max_new_tokens=1, 
            do_sample=True,     # ÎûúÎç§ ÏÉòÌîåÎßÅ ÏºúÍ∏∞
            temperature=1.0,    # 1.0 = ÌëúÏ§Ä ÌôïÎ•† Î∂ÑÌè¨ Îî∞Î¶Ñ
            top_k=50,           # ÏÉÅÏúÑ 50Í∞ú Ï§ëÏóêÏÑúÎßå ÏÉòÌîåÎßÅ (Ïù¥ÏÉÅÌïú Îã®Ïñ¥ Î∞©ÏßÄ)
            output_scores=True, 
            return_dict_in_generate=True
        )
    
    logits_rand = outputs_rand.scores[0][0][target_ids_tensor]
    prob_rand = F.softmax(logits_rand, dim=-1)
    pred_rand_idx = torch.argmax(prob_rand).item() # ÎûúÎç§ÌïòÍ≤å ÏÑ†ÌÉùÎêú Í≤É

    # ÏãúÍ∞ÅÌôîÏö© ÌôïÎ•†Í∞í Ï†ÄÏû• (Ïó¨Í∏∞ÏÑúÎäî 0Î≤à ÌÅ¥ÎûòÏä§ 'Left'Ïùò ÌôïÎ•†ÏùÑ Ï∂îÏ†ÅÌïúÎã§Í≥† Í∞ÄÏ†ï)
    # Ïã§Ï†úÎ°úÎäî CenterÎÇò RightÍ∞Ä Ï†ïÎãµÏùº ÏàòÎèÑ ÏûàÏßÄÎßå, 
    # 'ÌôïÎ•†Ïù¥ ÏñºÎßàÎÇò ÌùîÎì§Î¶¨ÎäîÏßÄ'Î•º Î≥¥Îäî Í≤ÉÏù¥ Î™©Ï†ÅÏù¥ÎØÄÎ°ú ÌïòÎÇòÎßå Ï∂îÏ†ÅÌï¥ÎèÑ Ï∂©Î∂ÑÌï®.
    prob_target_base = prob_base[0].item()
    prob_target_adapt = prob_adapt[0].item()
    prob_target_rand = prob_rand[0].item()

    results_log.append({
        "frame": frame_idx,
        "time": frame_idx / fps,
        "base_pred_idx": pred_base_idx,
        "adapt_pred_idx": pred_adapt_idx,
        "rand_pred_idx": pred_rand_idx,
        "prob_target_base": prob_target_base,
        "prob_target_adapt": prob_target_adapt,
        "prob_target_rand": prob_target_rand,
        "used_alpha": used_alpha
    })
    
    frame_idx += 1
    pbar.update(1)

cap.release()
pbar.close()

# Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•
df = pd.DataFrame(results_log)
df.to_csv("stress_test_full_data.csv", index=False)
print("üíæ Full data saved to 'stress_test_full_data.csv'")

# ==========================================
# 5. Top-5 Hardest Segment Mining & Visualization
# ==========================================
print("üîç Mining Top-5 Hardest Segments...")

# Baseline(Greedy)Ïùò ÏòàÏ∏°Ïù¥ Î∞îÎÄê ÏßÄÏ†ê(Flickering) Í≥ÑÏÇ∞
df['shifted'] = df['base_pred_idx'].shift(1)
df['flicker'] = (df['base_pred_idx'] != df['shifted']).astype(int)

# 5Ï¥à Íµ¨Í∞Ñ(ÏúàÎèÑÏö∞) ÎÇ¥ÏóêÏÑú ÌîåÎ¶¨Ïª§ÎßÅÏù¥ Í∞ÄÏû• Ïã¨Ìïú Í≥≥ Ï∞æÍ∏∞
window_sec = 5
window_size = int(window_sec * (fps / STRIDE)) # 5Ï¥àÏóê Ìï¥ÎãπÌïòÎäî Îç∞Ïù¥ÌÑ∞ Ìè¨Ïù∏Ìä∏ Ïàò

# Î°§ÎßÅ ÏúàÎèÑÏö∞Î°ú ÌîåÎ¶¨Ïª§ÎßÅ Ìï©Í≥Ñ Í≥ÑÏÇ∞
df['rolling_flicker'] = df['flicker'].rolling(window=window_size).sum()

# Top 5 Íµ¨Í∞Ñ Ï∞æÍ∏∞ (Í≤πÏπòÏßÄ ÏïäÍ≤å)
top_segments = []
temp_df = df.copy()

for i in range(5):
    if temp_df['rolling_flicker'].max() == 0: break
    
    max_idx = temp_df['rolling_flicker'].idxmax()
    start_idx = max(0, max_idx - window_size)
    end_idx = max_idx
    
    top_segments.append((start_idx, end_idx))
    
    # Ïù¥ÎØ∏ Ï∞æÏùÄ Íµ¨Í∞Ñ Ï£ºÎ≥Ä ÏßÄÏö∞Í∏∞
    clean_start = max(0, start_idx - window_size)
    clean_end = min(len(temp_df), end_idx + window_size)
    temp_df.loc[clean_start:clean_end, 'rolling_flicker'] = 0

print(f"‚úÖ Found {len(top_segments)} critical segments.")

# ÏãúÍ∞ÅÌôî Ìï®Ïàò
def plot_segment(segment_df, segment_id):
    plt.figure(figsize=(14, 6))
    
    times = segment_df['time']
    
    # 1. Baseline (Random Sampling): Ï¥àÎ°ùÏÉâ Ï†êÏÑ† (Í∞ÄÏû• Î∂àÏïàÏ†ïÌï®)
    plt.plot(times, segment_df['prob_target_rand'], color='green', linestyle=':', alpha=0.4, label='Baseline (Random Sampling)')
    
    # 2. Baseline (Greedy): Îπ®Í∞ÑÏÉâ Ï†êÏÑ† (Î∂àÏïàÏ†ïÌï®)
    plt.plot(times, segment_df['prob_target_base'], color='red', linestyle='--', alpha=0.6, label='Baseline (Greedy)')
    plt.scatter(times, segment_df['prob_target_base'], color='red', s=10, alpha=0.6)
    
    # 3. Ours (Adaptive): ÌååÎûÄÏÉâ Ïã§ÏÑ† (ÏïàÏ†ïÏ†ÅÏûÑ)
    plt.plot(times, segment_df['prob_target_adapt'], color='blue', linewidth=2.5, label='Ours (Adaptive)')
    
    # 4. Î∞©Ïñ¥ Í∏∞Ï†ú ÏûëÎèô ÏàúÍ∞Ñ (High Alpha) ÌëúÏãú
    high_alpha_mask = segment_df['used_alpha'] > 0.7
    if high_alpha_mask.any():
        plt.scatter(times[high_alpha_mask], segment_df.loc[high_alpha_mask, 'prob_target_adapt'], 
                   color='purple', s=40, marker='*', label='High Alpha (>0.7)', zorder=5)

    # TC Score (Greedy vs Ours) ÎπÑÍµê
    def calc_tc(preds):
        if len(preds) < 2: return 0.0
        return sum(1 for i in range(len(preds)-1) if preds[i] == preds[i+1]) / (len(preds)-1)
    
    tc_base = calc_tc(segment_df['base_pred_idx'].tolist())
    tc_ours = calc_tc(segment_df['adapt_pred_idx'].tolist())
    
    plt.title(f"Stress Test Case #{segment_id+1} (Time: {times.iloc[0]:.1f}s ~ {times.iloc[-1]:.1f}s)\nBaseline TC: {tc_base:.3f}  vs  Ours TC: {tc_ours:.3f} (Improvement: +{(tc_ours-tc_base)*100:.1f}%)", fontsize=14, fontweight='bold')
    plt.xlabel("Time (seconds)", fontsize=12)
    plt.ylabel("Prediction Confidence (Target: Left)", fontsize=12)
    plt.ylim(-0.05, 1.05)
    plt.legend(loc='lower right', fontsize=10)
    plt.grid(True, linestyle='--', alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(f"stress_test_case_{segment_id+1}.png", dpi=300)
    plt.close()

# Í∑∏ÎûòÌîÑ Í∑∏Î¶¨Í∏∞ Ïã§Ìñâ
for i, (start, end) in enumerate(top_segments):
    segment_data = df.iloc[start:end]
    plot_segment(segment_data, i)

print("üéâ All Done! Check 'stress_test_case_*.png' files.")